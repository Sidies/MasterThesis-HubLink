{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of the Literature Research Process\n",
    "\n",
    "This notebook contains details about the literature survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we are going to load the JSON file containing the literature research\n",
    "import os\n",
    "import json\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "data_dir = os.path.join(\"./extraction.json\")\n",
    "process_dir = os.path.join(\"../literature_survey/research_process.json\")\n",
    "references_dir = os.path.join(\"../literature_survey/research_process.json\")\n",
    "\n",
    "with open(os.path.join(current_dir, data_dir), \"r\", encoding=\"utf-8\") as f:\n",
    "    papers_data = json.load(f)\n",
    "\n",
    "with open(os.path.join(current_dir, process_dir), \"r\", encoding=\"utf-8\") as f:\n",
    "    process_data = json.load(f)\n",
    "    \n",
    "with open(os.path.join(current_dir, references_dir), \"r\", encoding=\"utf-8\") as f:\n",
    "    research_process = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Question Types by Paper Category and Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "# Using defaultdict allows us to avoid checking if a key exists in the dictionary\n",
    "# it automatically initializes the key with the default value (in this case, 0)\n",
    "# when a new key is encountered\n",
    "question_type_counts = defaultdict(int)\n",
    "paper_counts = defaultdict(int)\n",
    "\n",
    "for paper in papers_data:\n",
    "    paper_cat = paper.get(\"category\", \"Unknown\")\n",
    "    num_types = len(paper.get(\"types\", []))\n",
    "    question_type_counts[paper_cat] += num_types\n",
    "    paper_counts[paper_cat] += 1\n",
    "data = [\n",
    "    {\n",
    "        \"Category\": cat,\n",
    "        \"Number of Question Types\": question_type_counts[cat],\n",
    "        \"Number of Papers\": paper_counts[cat]\n",
    "    }\n",
    "    for cat in question_type_counts\n",
    "]\n",
    "analysis_overall_df = pd.DataFrame(data)\n",
    "\n",
    "total_question_types = analysis_overall_df[\"Number of Question Types\"].sum()\n",
    "total_papers = analysis_overall_df[\"Number of Papers\"].sum()\n",
    "\n",
    "total_row = pd.DataFrame([{\n",
    "    \"Category\": \"Total\",\n",
    "    \"Number of Question Types\": total_question_types,\n",
    "    \"Number of Papers\": total_papers\n",
    "}])\n",
    "analysis_overall_df = pd.concat([analysis_overall_df, total_row], ignore_index=True)\n",
    "\n",
    "# Sort the DataFrame by Category\n",
    "analysis_overall_df.sort_values(by=[\"Category\"], inplace=True)\n",
    "analysis_overall_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"Analysis: Total number of question types by paper category\")\n",
    "display(analysis_overall_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "# Using defaultdict allows us to avoid checking if a key exists in the dictionary\n",
    "# it automatically initializes the key with the default value (in this case, 0)\n",
    "# when a new key is encountered\n",
    "analysis_overall_counts = defaultdict(int)\n",
    "paper_overall_counts = defaultdict(int)\n",
    "\n",
    "for paper in papers_data:\n",
    "    paper_cat = paper.get(\"category\", \"Unknown\")\n",
    "    paper_dom = paper.get(\"domain\", \"Unknown\")\n",
    "    num_types = len(paper.get(\"types\", []))\n",
    "    analysis_overall_counts[(paper_cat, paper_dom)] += num_types\n",
    "    paper_overall_counts[(paper_cat, paper_dom)] += 1\n",
    "\n",
    "data = [\n",
    "    {\n",
    "        \"Category\": cat,\n",
    "        \"Domain\": dom,\n",
    "        \"Number of Question Types\": analysis_overall_counts[(cat, dom)],\n",
    "        \"Number of Papers\": paper_overall_counts[(cat, dom)]\n",
    "    }\n",
    "    for (cat, dom) in analysis_overall_counts\n",
    "]\n",
    "analysis_overall_df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate totals\n",
    "total_question_types = analysis_overall_df[\"Number of Question Types\"].sum()\n",
    "total_papers = analysis_overall_df[\"Number of Papers\"].sum()\n",
    "total_row = pd.DataFrame([{\n",
    "    \"Category\": \"Total\",\n",
    "    \"Domain\": \"\",\n",
    "    \"Number of Question Types\": total_question_types,\n",
    "    \"Number of Papers\": total_papers\n",
    "}])\n",
    "\n",
    "analysis_overall_df = pd.concat([analysis_overall_df, total_row], ignore_index=True)\n",
    "\n",
    "# Sort the DataFrame by Category and then by Domain\n",
    "analysis_overall_df.sort_values(by=[\"Category\", \"Domain\"], inplace=True)\n",
    "analysis_overall_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"Analysis: Total number of question types and papers by paper category and domain\")\n",
    "display(analysis_overall_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publication Year Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_counts = defaultdict(int)\n",
    "\n",
    "for paper in papers_data:\n",
    "    year = paper.get(\"year\", \"Unknown\")\n",
    "    year_counts[year] += 1\n",
    "\n",
    "data = [\n",
    "    {\"Year\": year, \"Number of Papers\": count}\n",
    "    for year, count in year_counts.items()\n",
    "]\n",
    "analysis_overall_df = pd.DataFrame(data)\n",
    "\n",
    "analysis_overall_df.sort_values(by=[\"Year\"], inplace=True, ascending=False)\n",
    "analysis_overall_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"Analysis: Number of papers published by year\")\n",
    "display(analysis_overall_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display as a bar chart and save as PDF\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(analysis_overall_df[\"Year\"], \n",
    "    analysis_overall_df[\"Number of Papers\"], \n",
    "    color=\"#79ab74\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Number of Papers\")\n",
    "plt.title(\"Number of Papers Published by Year\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.6)\n",
    "plt.yticks(range(0, max(analysis_overall_df[\"Number of Papers\"]) + 1))\n",
    "\n",
    "plt.savefig(\"papers_by_year.pdf\", bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of References\n",
    "In the following output, the distribution of references is shown. This data reveals the extent to which the classifications may have been informed by prior work.\n",
    "\n",
    "For this analysis, the \"references\" fields are used to gather which paper references another paper that is in the final list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we get the metadata\n",
    "reference_mapping = {}\n",
    "\n",
    "for iteration in research_process:\n",
    "    for paper_process in iteration.get(\"processing\", []):\n",
    "        title = paper_process.get(\"title\", \"No title\").lower()        \n",
    "        if not paper_process.get(\"added_to_final\", False):\n",
    "            continue\n",
    "        if reference_mapping.get(title) is None:\n",
    "                reference_mapping[title] = []\n",
    "        for reference in paper_process.get(\"references\", []):\n",
    "            reference_mapping[title].append(reference.lower())\n",
    "\n",
    "# Now we process each reference_mapping and only keep those references that also have a dict key entry\n",
    "for title, references in reference_mapping.items():\n",
    "    delete_idx = []\n",
    "    for idx, reference in enumerate(references):\n",
    "        if reference.lower() in reference_mapping.keys():\n",
    "            continue\n",
    "        delete_idx.append(idx)\n",
    "    for idx in reversed(delete_idx):\n",
    "        del references[idx]\n",
    "\n",
    "\n",
    "print(f\"Total length of references: {len(reference_mapping)}\")\n",
    "\n",
    "rows = []\n",
    "for idx, (title, references) in enumerate(reference_mapping.items()):\n",
    "    rows.append({\"title\": title, \"references\": references, \"amount\": len(references)})\n",
    "\n",
    "df_references = pd.DataFrame(rows)\n",
    "# sort by amount of references\n",
    "df_references = df_references.sort_values(by=[\"amount\"], ascending=False)\n",
    "df_references\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Citations\n",
    "In the following output, the distribution of citations is shown. This provides insight into the relative influence of each publication within this dataset.\n",
    "\n",
    "For this analysis, the \"references\" fields are used to gather which paper references another paper that is in the final list. The output is then inverted to show the number of citations per paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we get the metadata\n",
    "citation_mapping = {}\n",
    "for idx, (title, references) in enumerate(reference_mapping.items()):\n",
    "    for reference in references:\n",
    "        if citation_mapping.get(reference) is None:\n",
    "            citation_mapping[reference] = []\n",
    "        citation_mapping[reference].append(title)\n",
    "        \n",
    "rows = []\n",
    "for idx, (title, references) in enumerate(citation_mapping.items()):\n",
    "    rows.append({\"title\": title, \"citations\": references, \"amount\": len(references)})\n",
    "\n",
    "df_citations = pd.DataFrame(rows)\n",
    "# sort by amount of citations\n",
    "df_citations = df_citations.sort_values(by=[\"amount\"], ascending=False)\n",
    "df_citations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
