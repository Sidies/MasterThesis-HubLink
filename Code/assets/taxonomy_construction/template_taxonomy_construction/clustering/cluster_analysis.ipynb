{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Analysis\n",
    "\n",
    "This Notebook analyzes the manually created clusters of question types from the literature survey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Load the JSON files\n",
    "current_dir = os.getcwd()\n",
    "cluster_inc_dir = os.path.join(\"./cluster_increments.json\")\n",
    "extract_dir = os.path.join(\"../extraction/extraction.json\")\n",
    "references_dir = os.path.join(\"../literature_survey/research_process.json\")\n",
    "\n",
    "with open(os.path.join(current_dir, cluster_inc_dir), \"r\", encoding=\"utf-8\") as f:\n",
    "    cluster_increments = json.load(f)\n",
    "\n",
    "with open(os.path.join(current_dir, extract_dir), \"r\", encoding=\"utf-8\") as f:\n",
    "    extraction_mapping = json.load(f)\n",
    "\n",
    "with open(os.path.join(current_dir, references_dir), \"r\", encoding=\"utf-8\") as f:\n",
    "    research_process = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Iteration - Clusters and Types\n",
    "\n",
    "In the following output, the clusters of the first iteration are shown with their respective types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "types_from_extraction = {}\n",
    "for paper_data in extraction_mapping:\n",
    "    title = paper_data.get(\"title\", \"unknown\")\n",
    "    for type in paper_data.get(\"types\", []):\n",
    "        name = type.get(\"type\", \"unknown\")\n",
    "        types_from_extraction[(name, title)] = 1\n",
    "\n",
    "types_from_clustering = {}\n",
    "type_clusters = []\n",
    "name_source_mapping = set()\n",
    "for iteration in cluster_increments:\n",
    "    iteration_count = iteration.get(\"iteration\", -1)\n",
    "    if iteration_count != 1:\n",
    "        continue\n",
    "\n",
    "    for cluster in iteration.get(\"clusters\", []):\n",
    "        types = []\n",
    "        for item in cluster.get(\"types\", []):\n",
    "            name = item.get(\"name\", \"unknown\")\n",
    "            source = item.get(\"source\", \"unknown\")\n",
    "            types.append(name)\n",
    "            types_from_clustering[(name, source)] = 1\n",
    "            if (name, source) in name_source_mapping:\n",
    "                print(f\"Duplicate: {name} - {source}\")\n",
    "            name_source_mapping.add((name, source))\n",
    "        type_clusters.append(types)\n",
    "    \n",
    "rows = []\n",
    "for idx, types_list in enumerate(type_clusters):\n",
    "    rows.append({\"cluster id\": idx, \"types\": \" ||| \".join(types_list), \"count\": len(types_list)})\n",
    "\n",
    "print(f\"Total amount of types from extraction: {len(types_from_extraction)}\")\n",
    "\n",
    "# Missing types\n",
    "missing_types = set(types_from_extraction.keys()) - name_source_mapping\n",
    "for missing_type in missing_types:\n",
    "    print(f\"Missing type: {missing_type}\")\n",
    "\n",
    "print(f\"Total amount of clusters: {len(rows)}\")\n",
    "print(f\"Total amount of types: {sum([row['count'] for row in rows])}\")\n",
    "        \n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "df_types = pd.DataFrame(rows)\n",
    "df_types = df_types.sort_values(by=\"count\", ascending=False)\n",
    "df_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteration 1 - Clusters with Description\n",
    "In the following output, the clusters of the first iteration are shown with their respective types and descriptions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_descriptions = {}\n",
    "\n",
    "for paper in extraction_mapping:\n",
    "    paper_title = paper.get(\"title\", \"No title\")\n",
    "    for type_dict in paper.get(\"types\", []):\n",
    "        the_type = type_dict.get(\"type\", \"unknown\")\n",
    "        description = type_dict.get(\"description\", \"No description\")\n",
    "        type_descriptions[(paper_title, the_type)] = description\n",
    "\n",
    "\n",
    "clusters_with_descriptions = []\n",
    "\n",
    "for iteration in cluster_increments:\n",
    "    iteration_count = iteration.get(\"iteration\", -1)\n",
    "    if iteration_count != 1:\n",
    "        continue\n",
    "\n",
    "    for cluster in iteration.get(\"clusters\", []):\n",
    "        cluster_data = []\n",
    "        print(\"______________________\")\n",
    "        for item in cluster.get(\"types\", []):\n",
    "            print(\"     -------------------\")\n",
    "            name = item.get(\"name\", \"unknown\")\n",
    "            source = item.get(\"source\", \"unknown\")\n",
    "            description = type_descriptions.get((source, name), \"No Mapping Found\")\n",
    "            print(f\"    Name: {name}\")\n",
    "            print(f\"    Source: {source}\")\n",
    "            print(f\"    Description: {description}\")\n",
    "            if description == \"No Mapping Found\":\n",
    "                print(f\"No mapping found for {source} - {name}\")\n",
    "            cluster_data.append({\"name\": name, \"source\": source, \"description\": description})\n",
    "        \n",
    "        clusters_with_descriptions.append({\n",
    "            \"cluster_types_with_description\": cluster_data,\n",
    "        })        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Iteration 2 - Clusters with Description and Parent Clusters\n",
    "\n",
    "In the following output, the clusters of the second iteration are shown with their respective types, descriptions, and parent clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_descriptions = {}\n",
    "for paper in extraction_mapping:\n",
    "    paper_title = paper.get(\"title\", \"No title\")\n",
    "    for type_dict in paper.get(\"types\", []):\n",
    "        the_type = type_dict.get(\"type\", \"unknown\")\n",
    "        description = type_dict.get(\"description\", \"No description\")\n",
    "        type_descriptions[(paper_title, the_type)] = description\n",
    "\n",
    "\n",
    "grouped_clusters_with_description = []\n",
    "amount_of_clusters = 0\n",
    "for iteration in cluster_increments:\n",
    "    iteration_count = iteration.get(\"iteration\", -1)\n",
    "    if iteration_count != 2:\n",
    "        continue\n",
    "    \n",
    "    for cluster in iteration.get(\"clusters\", []):\n",
    "        cluster_info = cluster.get(\"info\", \"No info\")\n",
    "        print(\"______________________\")\n",
    "        print(f\"Cluster ID: {cluster.get('id', 'unknown')}\")\n",
    "        print(f\"Cluster Name: {cluster.get('name', 'unknown')}\")\n",
    "        print(f\"Cluster info: {cluster_info}\")\n",
    "        print(f\"Subclusters: {len(cluster.get('subclusters', []))}: \")\n",
    "        subcluster_data = []\n",
    "        for index, subcluster in enumerate(cluster.get(\"subclusters\", [])):\n",
    "            subcluster_name = subcluster.get(\"name\", \"unknown\")\n",
    "            subcluster_info = subcluster.get(\"info\", \"No info\")\n",
    "            subcluster_id = subcluster.get(\"id\", \"unknown\")\n",
    "            print(f\"     Subcluster ID: {subcluster_id}\")\n",
    "            print(f\"     Name: {subcluster_name}\")\n",
    "            print(f\"     Info: {subcluster_info}\")\n",
    "            print(\"     -------------------\")\n",
    "            cluster_data = []\n",
    "\n",
    "            for item in subcluster.get(\"types\", []):\n",
    "                name = item.get(\"name\", \"unknown\")\n",
    "                source = item.get(\"source\", \"unknown\")\n",
    "                description = type_descriptions.get((source, name), \"No Mapping Found\")\n",
    "                if description == \"No Mapping Found\":\n",
    "                    print(f\"No mapping found for {source} - {name}\")\n",
    "                cluster_data.append({\"name\": name, \"source\": source, \"description\": description})\n",
    "            subcluster_data.append({\n",
    "                \"cluster_types_with_description\": cluster_data,\n",
    "                \"subcluster_id\": subcluster_id,\n",
    "                \"subcluster_name\": subcluster_name,\n",
    "                \"subcluster_info\": subcluster_info,\n",
    "            })\n",
    "            \n",
    "        grouped_clusters_with_description.append(subcluster_data)\n",
    "print(f\"Amount of clusters: {amount_of_clusters}\")   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Analysis of Clusters\n",
    "\n",
    "In the following output, a total summary analysis is shown, including the number of clusters, types, and descriptions. The analysis also includes the number of clusters per type and the number of clusters per parent cluster.\n",
    "It allows to get a better understanding of where each cluster originates from and what their characteristics are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def print_with_occurence(prefix, data):\n",
    "    \"\"\"Helper Function to print the occurrence of items in a list.\"\"\"\n",
    "    count_dict = defaultdict(int)\n",
    "    for item in data:\n",
    "        count_dict[item] += 1\n",
    "    output_text = \"\"\n",
    "    for key, value in count_dict.items():\n",
    "        output_text += f\"{value}x {key}, \"\n",
    "    output_text = output_text[:-2]\n",
    "    print(f\"{prefix}: {output_text}\")\n",
    "    \n",
    "# -----------\n",
    "# Prepare the data for each iteration\n",
    "first_iteration = None\n",
    "second_iteration = None\n",
    "for iteration in cluster_increments:\n",
    "    iteration_count = iteration.get(\"iteration\", -1)\n",
    "    if iteration_count == 1:\n",
    "        first_iteration = iteration\n",
    "    if iteration_count == 2:\n",
    "        second_iteration = iteration\n",
    "\n",
    "for first_iteration_cluster in first_iteration.get(\"clusters\", []):\n",
    "    first_iteration_types = first_iteration_cluster.get(\"types\", [])\n",
    "        \n",
    "    has_match = False\n",
    "\n",
    "    for second_iteration_cluster in second_iteration.get(\"clusters\", []):\n",
    "        for second_iteration_subcluster in second_iteration_cluster.get(\"subclusters\", []):\n",
    "            second_iteration_types = second_iteration_subcluster.get(\"types\", [])\n",
    "\n",
    "            if len(first_iteration_types) != len(second_iteration_types):\n",
    "                continue\n",
    "\n",
    "            # Check if all types match\n",
    "            all_match = True\n",
    "            for first_iteration_type in first_iteration_types:\n",
    "                first_iteration_name = first_iteration_type.get(\"name\", \"unknown\")\n",
    "                has_type_match = False\n",
    "                for second_iteration_type in second_iteration_types:\n",
    "                    second_iteration_name = second_iteration_type.get(\"name\", \"unknown\")\n",
    "                    if first_iteration_name == second_iteration_name:\n",
    "                        has_type_match = True\n",
    "                        break\n",
    "                if not has_type_match:\n",
    "                    all_match = False\n",
    "                    break\n",
    "            if all_match:\n",
    "                has_match = True\n",
    "                break\n",
    "        if has_match:\n",
    "            break\n",
    "    if not has_match:\n",
    "        print(f\"First Iteration Types: {[type.get('name', 'unknown') for type in first_iteration_types]}\")\n",
    "        print(\"______________________\")\n",
    "# ----------\n",
    "# ----------\n",
    "# Create a mapping of metadata for each paper\n",
    "metadata_mapping = {}\n",
    "for paper in extraction_mapping:\n",
    "    title = paper.get(\"title\", \"No title\")\n",
    "    year = paper.get(\"year\", \"No year\")\n",
    "    authors = paper.get(\"authors\", \"No authors\")\n",
    "    doi = paper.get(\"doi\", \"No doi\")\n",
    "    category = paper.get(\"category\", \"No category\")\n",
    "    domain = paper.get(\"domain\", \"No domain\")\n",
    "    metadata_mapping[title] = {\n",
    "        \"year\": year,\n",
    "        \"authors\": authors,\n",
    "        \"doi\": doi,\n",
    "        \"category\": category,\n",
    "        \"domain\": domain,\n",
    "    }\n",
    "# ----------\n",
    "# ----------\n",
    "# Print the metadata for each cluster\n",
    "for iteration in cluster_increments:\n",
    "    if not iteration.get(\"iteration\", -1) == 2:\n",
    "        continue\n",
    "\n",
    "    for cluster in iteration.get(\"clusters\", []):\n",
    "        cluster_id = cluster.get(\"id\", \"unknown\")\n",
    "        cluster_name = cluster.get(\"name\", \"unknown\")\n",
    "        cluster_info = cluster.get(\"info\", \"No info\")\n",
    "        print(\"______________________\")\n",
    "        print(f\"Parent-Cluster ID: {cluster_id}\")\n",
    "        print(f\"Parent-Cluster Name: {cluster_name}\")\n",
    "        print(f\"Parent-Cluster Info: {cluster_info}\")\n",
    "        subclusters = cluster.get(\"subclusters\", [])\n",
    "        types = []\n",
    "        subcluster_names = []\n",
    "        sources = {}\n",
    "        domains = set()\n",
    "        years = set()\n",
    "        categories = set()\n",
    "        for subcluster in subclusters:\n",
    "            subcluster_types = subcluster.get(\"types\", [])\n",
    "            subcluster_id = subcluster.get(\"id\", \"unknown\")\n",
    "            subcluster_info = subcluster.get(\"info\", \"No info\")\n",
    "            subcluster_name = subcluster.get(\"name\", \"unknown\")\n",
    "            subcluster_names.append(subcluster_name)\n",
    "            for type_dict in subcluster_types:\n",
    "                name = type_dict.get(\"name\", \"unknown\")\n",
    "                source = type_dict.get(\"source\", \"unknown\")\n",
    "                domain = metadata_mapping.get(source, {}).get(\"domain\", \"unknown\")\n",
    "                year = metadata_mapping.get(source, {}).get(\"year\", -1)\n",
    "                category = metadata_mapping.get(source, {}).get(\"category\", \"unknown\")\n",
    "                types.append(name)\n",
    "                sources[source] = {\n",
    "                    \"domain\": domain,\n",
    "                    \"year\": year,\n",
    "                    \"category\": category\n",
    "                }\n",
    "                domains.add(domain)\n",
    "                years.add(year)\n",
    "                categories.add(category)\n",
    "        print(f\"Amount of subclusters: {len(subclusters)}\")\n",
    "        print(f\"Amount of types in all subclusters: {len(types)}\")\n",
    "        print(f\"Amount of different domains: {len(domains)}\")\n",
    "        print(f\"Amount of different years: {len(years)}\")\n",
    "        print(f\"Amount of different categories: {len(categories)}\")\n",
    "        print(f\"Amount of different sources: {len(sources)}\")\n",
    "        print(f\"Names of Subclusters: {subcluster_names}\")\n",
    "\n",
    "        src_domains = [source[\"domain\"] for source in sources.values()]\n",
    "        src_years = [source[\"year\"] for source in sources.values()]\n",
    "        src_categories = [source[\"category\"] for source in sources.values()]\n",
    "        src_names = list(sources.keys())\n",
    "        print_with_occurence(\"Domains\", src_domains)\n",
    "        print_with_occurence(\"Years\", src_years)\n",
    "        print_with_occurence(\"Categories\", src_categories)\n",
    "        print(\"Sources: \", src_names)\n",
    "# -----------\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
