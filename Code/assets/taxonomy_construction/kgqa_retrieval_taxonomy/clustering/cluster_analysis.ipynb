{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Analysis\n",
    "\n",
    "This Notebook analyzes the manually created clusters of question types from the literature survey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Load the JSON files\n",
    "current_dir = os.getcwd()\n",
    "cluster_inc_dir = os.path.join(\"./cluster_increments.json\")\n",
    "extract_dir = os.path.join(\"../extraction/extraction.json\")\n",
    "references_dir = os.path.join(\"../literature_survey/research_process.json\")\n",
    "\n",
    "with open(os.path.join(current_dir, cluster_inc_dir), \"r\", encoding=\"utf-8\") as f:\n",
    "    cluster_increments = json.load(f)\n",
    "\n",
    "with open(os.path.join(current_dir, extract_dir), \"r\", encoding=\"utf-8\") as f:\n",
    "    extraction_mapping = json.load(f)\n",
    "\n",
    "with open(os.path.join(current_dir, references_dir), \"r\", encoding=\"utf-8\") as f:\n",
    "    research_process = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Iteration - Clusters and Types\n",
    "\n",
    "In the following output, the clusters of the first iteration are shown with their respective types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total amount of types from extraction: 227\n",
      "Total amount of clusters: 96\n",
      "Total amount of types: 227\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster id</th>\n",
       "      <th>types</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Boolean ||| Boolean ||| Boolean ||| Ask ||| Yes/No ||| Affirm_MoreTuples ||| Affirm ||| Affirm_3Term ||| YesNo ||| Boolean</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Single Fact ||| Question Content - Factoid ||| single fact ||| Single Fact with Type ||| Normal ||| Single Fact ||| Normal</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Human ||| Person ||| Social ||| Human ||| Human ||| Human Description ||| Answer Type - Person</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>Causality - Causality ||| Causality-Comparative ||| Causality-Comparative Interaction ||| Third Order -Contingencies ||| Causality ||| Causality - Comparative interactions ||| Causal</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Numeric Value ||| Quantity ||| Quantification Questions ||| Numeric ||| Many ||| Many-Class ||| Answer Type - Number</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Location ||| Location ||| Location ||| Location ||| Answer Type - Location ||| Location ||| Location</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>What-When ||| What-Who ||| WHAT ||| What ||| What ||| What</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>Exploratory - Existence ||| Exploratory - Description and Classification ||| Exploratory - Descriptive-Comparative ||| Research Approach - Knowledge Goal ||| Existence ||| Feasibility Study or Exploration</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Union ||| Listing ||| List Questions ||| List ||| Resource List Typed ||| Resource List Untyped</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Count ||| Question Content - Non-Factoid - counting ||| Base-Rate - Frequency and Distribution ||| Count ||| Count based ||| Number Count</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>Who-What ||| WHO ||| Who ||| Who ||| Who</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>53</td>\n",
       "      <td>Comparison ||| Comparative ||| Second Order - Comparisons ||| Compare ||| Descriptive - Comparative</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Description ||| Base-Rate - Descriptive-Process ||| Description and Classification ||| Description ||| Descriptive</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>Date ||| Month ||| Answer Type - Date ||| Date ||| Date</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>Which-Where ||| WHERE ||| Where ||| Where ||| Where</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>Organization ||| Human Groups ||| Answer Type - Organization ||| Organization</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>Answer Type - Undefined ||| Unknown ||| Miscellaneous ||| Fourth Order -Extra</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>Question Content - Non-Factoid - Temporal ||| Trends over Time ||| Temporal Aspect ||| Temporal Aggregators</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>Orkg Content - Paper based ||| Orkg Content - Comparison based ||| SparQL Characteristics ||| Number Property</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Multi Facts ||| Question Content - Non-Factoid - sequence of facts ||| Multi Fact ||| Combining</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Double Intent ||| Two Intention ||| Composition ||| And/Or</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>Time ||| Time ||| Time ||| Answer Type - Time</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Superlative/Comparative ||| Question Content - Non-Factoid - Superlatives ||| Superlatives ||| Question Content - Non-Factoid - Minimum or Maximum</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>WHY ||| Why ||| Why</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>How ||| HowWhy ||| How</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>Factual Questions ||| Evidence-Based ||| Accuracy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>72</td>\n",
       "      <td>Relationship ||| UnknRel ||| Entity-relationship Questions</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>Other Named Entity ||| Other ||| Other</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Entity ||| Entity ||| Entities</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>80</td>\n",
       "      <td>Definition ||| Definition ||| Answer Type - Definition</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>Monetary Amount ||| Answer Type - Money ||| Answer Type - Price</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51</td>\n",
       "      <td>String Operation ||| String</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Disambiguation ||| Combine</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>Answer Type ||| Answer Type</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>54</td>\n",
       "      <td>Experience ||| Knowledge</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>66</td>\n",
       "      <td>Question Analysis/Focus ||| Focus</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>69</td>\n",
       "      <td>Conversational ||| Zero Order</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Negation ||| Question Content - Non-Factoid - Negation</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>Reason ||| Answer Type - Reason</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>Question Content - Non-Factoid - Ranking ||| Ranking</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>Whom ||| Whom</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>Linear Measure ||| Answer Type - Distance</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>Which-What ||| Which</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>82</td>\n",
       "      <td>UnknTerm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>71</td>\n",
       "      <td>Design</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>When</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>73</td>\n",
       "      <td>Actor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>Technology</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75</td>\n",
       "      <td>Activity</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>Software System</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Double Negation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>78</td>\n",
       "      <td>Asking Point (AP)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>79</td>\n",
       "      <td>Expected Answer Type (EAT)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Abbreviation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>81</td>\n",
       "      <td>request questions</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>Generalization or Characterization</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83</td>\n",
       "      <td>ThreeTerm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>84</td>\n",
       "      <td>Human Relations</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>85</td>\n",
       "      <td>Multilabel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>Name</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>87</td>\n",
       "      <td>Answer Type - NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>88</td>\n",
       "      <td>Answer Type - Title</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>89</td>\n",
       "      <td>Answer Type - Manner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90</td>\n",
       "      <td>Predictive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91</td>\n",
       "      <td>Bibliometric Numbers</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>92</td>\n",
       "      <td>Research Works</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>93</td>\n",
       "      <td>Resource Typed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>Resource Untyped</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70</td>\n",
       "      <td>First Order - Properties</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>Question Type</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>Whose</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>Procedure or Technique</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>Qualitative or Descriptive Model</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>Empirical Model</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>Analytic Model</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>Tool or Notation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>Specific Solution, Prototype, or Judgment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>Report</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>Design, Evaluation, or Analysis of a particular Instance</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>Method for Analysis or Evaluation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>Fact with Qualifiers</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>Method or Means of Development</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>Duration</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>55</td>\n",
       "      <td>Debate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>56</td>\n",
       "      <td>Aggregation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>Motivation - Problem Solving</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>58</td>\n",
       "      <td>Motivation - Gap Spotting</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59</td>\n",
       "      <td>Motivation - Problematization</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>60</td>\n",
       "      <td>Problem Statement</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>61</td>\n",
       "      <td>Usage of RQ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>62</td>\n",
       "      <td>Types of RQ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>63</td>\n",
       "      <td>Research Activities - Mode of Inquiry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>64</td>\n",
       "      <td>Theory-in-Use</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>Outcome Artifacts</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>Clause</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cluster id  \\\n",
       "2            2   \n",
       "0            0   \n",
       "13          13   \n",
       "49          49   \n",
       "15          15   \n",
       "14          14   \n",
       "16          16   \n",
       "48          48   \n",
       "7            7   \n",
       "5            5   \n",
       "20          20   \n",
       "53          53   \n",
       "12          12   \n",
       "28          28   \n",
       "18          18   \n",
       "33          33   \n",
       "30          30   \n",
       "27          27   \n",
       "25          25   \n",
       "1            1   \n",
       "8            8   \n",
       "77          77   \n",
       "6            6   \n",
       "21          21   \n",
       "22          22   \n",
       "35          35   \n",
       "72          72   \n",
       "29          29   \n",
       "11          11   \n",
       "80          80   \n",
       "32          32   \n",
       "51          51   \n",
       "9            9   \n",
       "68          68   \n",
       "54          54   \n",
       "66          66   \n",
       "69          69   \n",
       "3            3   \n",
       "52          52   \n",
       "26          26   \n",
       "24          24   \n",
       "31          31   \n",
       "19          19   \n",
       "82          82   \n",
       "71          71   \n",
       "17          17   \n",
       "73          73   \n",
       "74          74   \n",
       "75          75   \n",
       "76          76   \n",
       "4            4   \n",
       "78          78   \n",
       "79          79   \n",
       "10          10   \n",
       "81          81   \n",
       "39          39   \n",
       "83          83   \n",
       "84          84   \n",
       "85          85   \n",
       "86          86   \n",
       "87          87   \n",
       "88          88   \n",
       "89          89   \n",
       "90          90   \n",
       "91          91   \n",
       "92          92   \n",
       "93          93   \n",
       "94          94   \n",
       "70          70   \n",
       "67          67   \n",
       "23          23   \n",
       "40          40   \n",
       "41          41   \n",
       "42          42   \n",
       "43          43   \n",
       "44          44   \n",
       "45          45   \n",
       "46          46   \n",
       "47          47   \n",
       "38          38   \n",
       "37          37   \n",
       "50          50   \n",
       "36          36   \n",
       "34          34   \n",
       "55          55   \n",
       "56          56   \n",
       "57          57   \n",
       "58          58   \n",
       "59          59   \n",
       "60          60   \n",
       "61          61   \n",
       "62          62   \n",
       "63          63   \n",
       "64          64   \n",
       "65          65   \n",
       "95          95   \n",
       "\n",
       "                                                                                                                                                                                                           types  \\\n",
       "2                                                                                     Boolean ||| Boolean ||| Boolean ||| Ask ||| Yes/No ||| Affirm_MoreTuples ||| Affirm ||| Affirm_3Term ||| YesNo ||| Boolean   \n",
       "0                                                                                     Single Fact ||| Question Content - Factoid ||| single fact ||| Single Fact with Type ||| Normal ||| Single Fact ||| Normal   \n",
       "13                                                                                                                Human ||| Person ||| Social ||| Human ||| Human ||| Human Description ||| Answer Type - Person   \n",
       "49                        Causality - Causality ||| Causality-Comparative ||| Causality-Comparative Interaction ||| Third Order -Contingencies ||| Causality ||| Causality - Comparative interactions ||| Causal   \n",
       "15                                                                                          Numeric Value ||| Quantity ||| Quantification Questions ||| Numeric ||| Many ||| Many-Class ||| Answer Type - Number   \n",
       "14                                                                                                          Location ||| Location ||| Location ||| Location ||| Answer Type - Location ||| Location ||| Location   \n",
       "16                                                                                                                                                    What-When ||| What-Who ||| WHAT ||| What ||| What ||| What   \n",
       "48  Exploratory - Existence ||| Exploratory - Description and Classification ||| Exploratory - Descriptive-Comparative ||| Research Approach - Knowledge Goal ||| Existence ||| Feasibility Study or Exploration   \n",
       "7                                                                                                                Union ||| Listing ||| List Questions ||| List ||| Resource List Typed ||| Resource List Untyped   \n",
       "5                                                                      Count ||| Question Content - Non-Factoid - counting ||| Base-Rate - Frequency and Distribution ||| Count ||| Count based ||| Number Count   \n",
       "20                                                                                                                                                                      Who-What ||| WHO ||| Who ||| Who ||| Who   \n",
       "53                                                                                                           Comparison ||| Comparative ||| Second Order - Comparisons ||| Compare ||| Descriptive - Comparative   \n",
       "12                                                                                            Description ||| Base-Rate - Descriptive-Process ||| Description and Classification ||| Description ||| Descriptive   \n",
       "28                                                                                                                                                       Date ||| Month ||| Answer Type - Date ||| Date ||| Date   \n",
       "18                                                                                                                                                           Which-Where ||| WHERE ||| Where ||| Where ||| Where   \n",
       "33                                                                                                                                 Organization ||| Human Groups ||| Answer Type - Organization ||| Organization   \n",
       "30                                                                                                                                 Answer Type - Undefined ||| Unknown ||| Miscellaneous ||| Fourth Order -Extra   \n",
       "27                                                                                                   Question Content - Non-Factoid - Temporal ||| Trends over Time ||| Temporal Aspect ||| Temporal Aggregators   \n",
       "25                                                                                                 Orkg Content - Paper based ||| Orkg Content - Comparison based ||| SparQL Characteristics ||| Number Property   \n",
       "1                                                                                                                Multi Facts ||| Question Content - Non-Factoid - sequence of facts ||| Multi Fact ||| Combining   \n",
       "8                                                                                                                                                     Double Intent ||| Two Intention ||| Composition ||| And/Or   \n",
       "77                                                                                                                                                                 Time ||| Time ||| Time ||| Answer Type - Time   \n",
       "6                                                             Superlative/Comparative ||| Question Content - Non-Factoid - Superlatives ||| Superlatives ||| Question Content - Non-Factoid - Minimum or Maximum   \n",
       "21                                                                                                                                                                                           WHY ||| Why ||| Why   \n",
       "22                                                                                                                                                                                        How ||| HowWhy ||| How   \n",
       "35                                                                                                                                                             Factual Questions ||| Evidence-Based ||| Accuracy   \n",
       "72                                                                                                                                                    Relationship ||| UnknRel ||| Entity-relationship Questions   \n",
       "29                                                                                                                                                                        Other Named Entity ||| Other ||| Other   \n",
       "11                                                                                                                                                                                Entity ||| Entity ||| Entities   \n",
       "80                                                                                                                                                        Definition ||| Definition ||| Answer Type - Definition   \n",
       "32                                                                                                                                               Monetary Amount ||| Answer Type - Money ||| Answer Type - Price   \n",
       "51                                                                                                                                                                                   String Operation ||| String   \n",
       "9                                                                                                                                                                                     Disambiguation ||| Combine   \n",
       "68                                                                                                                                                                                   Answer Type ||| Answer Type   \n",
       "54                                                                                                                                                                                      Experience ||| Knowledge   \n",
       "66                                                                                                                                                                             Question Analysis/Focus ||| Focus   \n",
       "69                                                                                                                                                                                 Conversational ||| Zero Order   \n",
       "3                                                                                                                                                         Negation ||| Question Content - Non-Factoid - Negation   \n",
       "52                                                                                                                                                                               Reason ||| Answer Type - Reason   \n",
       "26                                                                                                                                                          Question Content - Non-Factoid - Ranking ||| Ranking   \n",
       "24                                                                                                                                                                                                 Whom ||| Whom   \n",
       "31                                                                                                                                                                     Linear Measure ||| Answer Type - Distance   \n",
       "19                                                                                                                                                                                          Which-What ||| Which   \n",
       "82                                                                                                                                                                                                      UnknTerm   \n",
       "71                                                                                                                                                                                                        Design   \n",
       "17                                                                                                                                                                                                          When   \n",
       "73                                                                                                                                                                                                         Actor   \n",
       "74                                                                                                                                                                                                    Technology   \n",
       "75                                                                                                                                                                                                      Activity   \n",
       "76                                                                                                                                                                                               Software System   \n",
       "4                                                                                                                                                                                                Double Negation   \n",
       "78                                                                                                                                                                                             Asking Point (AP)   \n",
       "79                                                                                                                                                                                    Expected Answer Type (EAT)   \n",
       "10                                                                                                                                                                                                  Abbreviation   \n",
       "81                                                                                                                                                                                             request questions   \n",
       "39                                                                                                                                                                            Generalization or Characterization   \n",
       "83                                                                                                                                                                                                     ThreeTerm   \n",
       "84                                                                                                                                                                                               Human Relations   \n",
       "85                                                                                                                                                                                                    Multilabel   \n",
       "86                                                                                                                                                                                                          Name   \n",
       "87                                                                                                                                                                                             Answer Type - NNP   \n",
       "88                                                                                                                                                                                           Answer Type - Title   \n",
       "89                                                                                                                                                                                          Answer Type - Manner   \n",
       "90                                                                                                                                                                                                    Predictive   \n",
       "91                                                                                                                                                                                          Bibliometric Numbers   \n",
       "92                                                                                                                                                                                                Research Works   \n",
       "93                                                                                                                                                                                                Resource Typed   \n",
       "94                                                                                                                                                                                              Resource Untyped   \n",
       "70                                                                                                                                                                                      First Order - Properties   \n",
       "67                                                                                                                                                                                                 Question Type   \n",
       "23                                                                                                                                                                                                         Whose   \n",
       "40                                                                                                                                                                                        Procedure or Technique   \n",
       "41                                                                                                                                                                                                   Instruction   \n",
       "42                                                                                                                                                                              Qualitative or Descriptive Model   \n",
       "43                                                                                                                                                                                               Empirical Model   \n",
       "44                                                                                                                                                                                                Analytic Model   \n",
       "45                                                                                                                                                                                              Tool or Notation   \n",
       "46                                                                                                                                                                     Specific Solution, Prototype, or Judgment   \n",
       "47                                                                                                                                                                                                        Report   \n",
       "38                                                                                                                                                      Design, Evaluation, or Analysis of a particular Instance   \n",
       "37                                                                                                                                                                             Method for Analysis or Evaluation   \n",
       "50                                                                                                                                                                                          Fact with Qualifiers   \n",
       "36                                                                                                                                                                                Method or Means of Development   \n",
       "34                                                                                                                                                                                                      Duration   \n",
       "55                                                                                                                                                                                                        Debate   \n",
       "56                                                                                                                                                                                                   Aggregation   \n",
       "57                                                                                                                                                                                  Motivation - Problem Solving   \n",
       "58                                                                                                                                                                                     Motivation - Gap Spotting   \n",
       "59                                                                                                                                                                                 Motivation - Problematization   \n",
       "60                                                                                                                                                                                             Problem Statement   \n",
       "61                                                                                                                                                                                                   Usage of RQ   \n",
       "62                                                                                                                                                                                                   Types of RQ   \n",
       "63                                                                                                                                                                         Research Activities - Mode of Inquiry   \n",
       "64                                                                                                                                                                                                 Theory-in-Use   \n",
       "65                                                                                                                                                                                             Outcome Artifacts   \n",
       "95                                                                                                                                                                                                        Clause   \n",
       "\n",
       "    count  \n",
       "2      10  \n",
       "0       7  \n",
       "13      7  \n",
       "49      7  \n",
       "15      7  \n",
       "14      7  \n",
       "16      6  \n",
       "48      6  \n",
       "7       6  \n",
       "5       6  \n",
       "20      5  \n",
       "53      5  \n",
       "12      5  \n",
       "28      5  \n",
       "18      5  \n",
       "33      4  \n",
       "30      4  \n",
       "27      4  \n",
       "25      4  \n",
       "1       4  \n",
       "8       4  \n",
       "77      4  \n",
       "6       4  \n",
       "21      3  \n",
       "22      3  \n",
       "35      3  \n",
       "72      3  \n",
       "29      3  \n",
       "11      3  \n",
       "80      3  \n",
       "32      3  \n",
       "51      2  \n",
       "9       2  \n",
       "68      2  \n",
       "54      2  \n",
       "66      2  \n",
       "69      2  \n",
       "3       2  \n",
       "52      2  \n",
       "26      2  \n",
       "24      2  \n",
       "31      2  \n",
       "19      2  \n",
       "82      1  \n",
       "71      1  \n",
       "17      1  \n",
       "73      1  \n",
       "74      1  \n",
       "75      1  \n",
       "76      1  \n",
       "4       1  \n",
       "78      1  \n",
       "79      1  \n",
       "10      1  \n",
       "81      1  \n",
       "39      1  \n",
       "83      1  \n",
       "84      1  \n",
       "85      1  \n",
       "86      1  \n",
       "87      1  \n",
       "88      1  \n",
       "89      1  \n",
       "90      1  \n",
       "91      1  \n",
       "92      1  \n",
       "93      1  \n",
       "94      1  \n",
       "70      1  \n",
       "67      1  \n",
       "23      1  \n",
       "40      1  \n",
       "41      1  \n",
       "42      1  \n",
       "43      1  \n",
       "44      1  \n",
       "45      1  \n",
       "46      1  \n",
       "47      1  \n",
       "38      1  \n",
       "37      1  \n",
       "50      1  \n",
       "36      1  \n",
       "34      1  \n",
       "55      1  \n",
       "56      1  \n",
       "57      1  \n",
       "58      1  \n",
       "59      1  \n",
       "60      1  \n",
       "61      1  \n",
       "62      1  \n",
       "63      1  \n",
       "64      1  \n",
       "65      1  \n",
       "95      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "types_from_extraction = {}\n",
    "for paper_data in extraction_mapping:\n",
    "    title = paper_data.get(\"title\", \"unknown\")\n",
    "    for type in paper_data.get(\"types\", []):\n",
    "        name = type.get(\"type\", \"unknown\")\n",
    "        types_from_extraction[(name, title)] = 1\n",
    "\n",
    "types_from_clustering = {}\n",
    "type_clusters = []\n",
    "name_source_mapping = set()\n",
    "for iteration in cluster_increments:\n",
    "    iteration_count = iteration.get(\"iteration\", -1)\n",
    "    if iteration_count != 1:\n",
    "        continue\n",
    "\n",
    "    for cluster in iteration.get(\"clusters\", []):\n",
    "        types = []\n",
    "        for item in cluster.get(\"types\", []):\n",
    "            name = item.get(\"name\", \"unknown\")\n",
    "            source = item.get(\"source\", \"unknown\")\n",
    "            types.append(name)\n",
    "            types_from_clustering[(name, source)] = 1\n",
    "            if (name, source) in name_source_mapping:\n",
    "                print(f\"Duplicate: {name} - {source}\")\n",
    "            name_source_mapping.add((name, source))\n",
    "        type_clusters.append(types)\n",
    "    \n",
    "rows = []\n",
    "for idx, types_list in enumerate(type_clusters):\n",
    "    rows.append({\"cluster id\": idx, \"types\": \" ||| \".join(types_list), \"count\": len(types_list)})\n",
    "\n",
    "print(f\"Total amount of types from extraction: {len(types_from_extraction)}\")\n",
    "\n",
    "# Missing types\n",
    "missing_types = set(types_from_extraction.keys()) - name_source_mapping\n",
    "for missing_type in missing_types:\n",
    "    print(f\"Missing type: {missing_type}\")\n",
    "\n",
    "print(f\"Total amount of clusters: {len(rows)}\")\n",
    "print(f\"Total amount of types: {sum([row['count'] for row in rows])}\")\n",
    "        \n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "df_types = pd.DataFrame(rows)\n",
    "df_types = df_types.sort_values(by=\"count\", ascending=False)\n",
    "df_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteration 1 - Clusters with Description\n",
    "In the following output, the clusters of the first iteration are shown with their respective types and descriptions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________\n",
      "     -------------------\n",
      "    Name: Single Fact\n",
      "    Source: DBLP-QuAD: A Question Answering Dataset over the DBLP Scholarly Knowledge Graph\n",
      "    Description: Related to questions that can be answered with a single fact from the Knowledge graph\n",
      "     -------------------\n",
      "    Name: Question Content - Factoid\n",
      "    Source: The SciQA Scientific Question Answering Benchmark for Scholarly Knowledge\n",
      "    Description: A factoid question type is assumed to have an explicit Asking Point mapping to an entity in the graph.\n",
      "     -------------------\n",
      "    Name: single fact\n",
      "    Source: LC-QuAD 2.0: A Large Dataset for Complex Question Answering over Wikidata and Dbpedia\n",
      "    Description: If the question requires a single fact to be retrieved.\n",
      "     -------------------\n",
      "    Name: Single Fact with Type\n",
      "    Source: LC-QuAD 2.0: A Large Dataset for Complex Question Answering over Wikidata and Dbpedia\n",
      "    Description: If the question requires a single fact to be retrieved and imposes an additional type constraint.\n",
      "     -------------------\n",
      "    Name: Normal\n",
      "    Source: Question Answering on Scholarly Knowledge Graphs\n",
      "    Description: Requires only one fact from the graph.\n",
      "     -------------------\n",
      "    Name: Single Fact\n",
      "    Source: Large-scale Simple Question Answering with Memory Networks\n",
      "    Description: Questions that require a single fact to be retrieved.\n",
      "     -------------------\n",
      "    Name: Normal\n",
      "    Source: Ripple Down Rules for question answering\n",
      "    Description: Defined as a standard question where one main part is missing that needs to be provided in the answer\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Multi Facts\n",
      "    Source: DBLP-QuAD: A Question Answering Dataset over the DBLP Scholarly Knowledge Graph\n",
      "    Description: Requires connection of two or more facts to derive the answer.\n",
      "     -------------------\n",
      "    Name: Question Content - Non-Factoid - sequence of facts\n",
      "    Source: The SciQA Scientific Question Answering Benchmark for Scholarly Knowledge\n",
      "    Description: A factoid question type that has multiple mappings to the graph.\n",
      "     -------------------\n",
      "    Name: Multi Fact\n",
      "    Source: LC-QuAD 2.0: A Large Dataset for Complex Question Answering over Wikidata and Dbpedia\n",
      "    Description: If the question requires multiple facts to be retrieved.\n",
      "     -------------------\n",
      "    Name: Combining\n",
      "    Source: Question Answering on Scholarly Knowledge Graphs\n",
      "    Description: Combination of information that requires multiple facts from the graph to collect the answer to the question\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Boolean\n",
      "    Source: DBLP-QuAD: A Question Answering Dataset over the DBLP Scholarly Knowledge Graph\n",
      "    Description: Expects a \"Yes\" or a \"No\" as an answer.\n",
      "     -------------------\n",
      "    Name: Boolean\n",
      "    Source: The SciQA Scientific Question Answering Benchmark for Scholarly Knowledge\n",
      "    Description: Question expecting a yes or a no.\n",
      "     -------------------\n",
      "    Name: Boolean\n",
      "    Source: LC-QuAD 2.0: A Large Dataset for Complex Question Answering over Wikidata and Dbpedia\n",
      "    Description: Expects a \"Yes\" or a \"No\" as an answer.\n",
      "     -------------------\n",
      "    Name: Ask\n",
      "    Source: Question Answering on Scholarly Knowledge Graphs\n",
      "    Description: Expects a 'Yes' or a 'No' as an answer.\n",
      "     -------------------\n",
      "    Name: Yes/No\n",
      "    Source: A Comparative Study of Question Answering over Knowledge Bases\n",
      "    Description: Questions that expect a yes or a no as anwer.\n",
      "     -------------------\n",
      "    Name: Affirm_MoreTuples\n",
      "    Source: Ripple Down Rules for question answering\n",
      "    Description: Classifies questions that expect a Yes or a No while asking for multiple things\n",
      "     -------------------\n",
      "    Name: Affirm\n",
      "    Source: Ripple Down Rules for question answering\n",
      "    Description: Questions that can be answered with Yes or No.\n",
      "     -------------------\n",
      "    Name: Affirm_3Term\n",
      "    Source: Ripple Down Rules for question answering\n",
      "    Description: ThreeTerm type that is also affirmative, meaning it can be answered with a yes or no.\n",
      "     -------------------\n",
      "    Name: YesNo\n",
      "    Source: Ripple Down Rules for question answering\n",
      "    Description: Questions that can be answered with a Yes or a No.\n",
      "     -------------------\n",
      "    Name: Boolean\n",
      "    Source: What is in the KGQA Benchmark Datasets? Survey on Challenges in Datasets for Question Answering on Knowledge Graphs\n",
      "    Description: Resulting from an ASK question\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Negation\n",
      "    Source: DBLP-QuAD: A Question Answering Dataset over the DBLP Scholarly Knowledge Graph\n",
      "    Description: Negates the answer to a boolean type\n",
      "     -------------------\n",
      "    Name: Question Content - Non-Factoid - Negation\n",
      "    Source: The SciQA Scientific Question Answering Benchmark for Scholarly Knowledge\n",
      "    Description: No further description.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Double Negation\n",
      "    Source: DBLP-QuAD: A Question Answering Dataset over the DBLP Scholarly Knowledge Graph\n",
      "    Description: Requires to negate the boolean question twice\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Count\n",
      "    Source: DBLP-QuAD: A Question Answering Dataset over the DBLP Scholarly Knowledge Graph\n",
      "    Description: Quantifies the amount of occurrences of facts in the graph\n",
      "     -------------------\n",
      "    Name: Question Content - Non-Factoid - counting\n",
      "    Source: The SciQA Scientific Question Answering Benchmark for Scholarly Knowledge\n",
      "    Description: No further description.\n",
      "     -------------------\n",
      "    Name: Base-Rate - Frequency and Distribution\n",
      "    Source: Selecting Empirical Methods for Software Engineering Research\n",
      "    Description: Relates to questions that seek to quantify the phenomenon. For example How often does X occur? or What is the average amount of X?\n",
      "     -------------------\n",
      "    Name: Count\n",
      "    Source: LC-QuAD 2.0: A Large Dataset for Complex Question Answering over Wikidata and Dbpedia\n",
      "    Description: Questions that require counting facts within the graph.\n",
      "     -------------------\n",
      "    Name: Count based\n",
      "    Source: 10th Question Answering over Linked Data (QALD) Challenge\n",
      "    Description: (e.g., How many grand-children did Jacques Cousteau have?)\n",
      "     -------------------\n",
      "    Name: Number Count\n",
      "    Source: What is in the KGQA Benchmark Datasets? Survey on Challenges in Datasets for Question Answering on Knowledge Graphs\n",
      "    Description: A number resulting from a COUNT operator in the SPARQL query\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Superlative/Comparative\n",
      "    Source: DBLP-QuAD: A Question Answering Dataset over the DBLP Scholarly Knowledge Graph\n",
      "    Description: Include two types of question. The first is about asking the maximum and minimum for a subject. The comparative question compares values between two subjects\n",
      "     -------------------\n",
      "    Name: Question Content - Non-Factoid - Superlatives\n",
      "    Source: The SciQA Scientific Question Answering Benchmark for Scholarly Knowledge\n",
      "    Description: No further description.\n",
      "     -------------------\n",
      "    Name: Superlatives\n",
      "    Source: 10th Question Answering over Linked Data (QALD) Challenge\n",
      "    Description: (e.g., Which poet wrote the most books?)\n",
      "     -------------------\n",
      "    Name: Question Content - Non-Factoid - Minimum or Maximum\n",
      "    Source: The SciQA Scientific Question Answering Benchmark for Scholarly Knowledge\n",
      "    Description: No further description.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Union\n",
      "    Source: DBLP-QuAD: A Question Answering Dataset over the DBLP Scholarly Knowledge Graph\n",
      "    Description: Covers questions with a single intend but for multiple facts in the graph at the same time, which includes listing multiple facts\n",
      "     -------------------\n",
      "    Name: Listing\n",
      "    Source: Question Answering on Scholarly Knowledge Graphs\n",
      "    Description: Related to queries that list elements of information from the graph\n",
      "     -------------------\n",
      "    Name: List Questions\n",
      "    Source: Large-scale Simple Question Answering with Memory Networks\n",
      "    Description: Questions that expect more than one answer.\n",
      "     -------------------\n",
      "    Name: List\n",
      "    Source: Ripple Down Rules for question answering\n",
      "    Description: Contains words like \"give\", \"show\", \"tell\", \"find\" and \"list\".\n",
      "     -------------------\n",
      "    Name: Resource List Typed\n",
      "    Source: What is in the KGQA Benchmark Datasets? Survey on Challenges in Datasets for Question Answering on Knowledge Graphs\n",
      "    Description: A list of resources of a specific type\n",
      "     -------------------\n",
      "    Name: Resource List Untyped\n",
      "    Source: What is in the KGQA Benchmark Datasets? Survey on Challenges in Datasets for Question Answering on Knowledge Graphs\n",
      "    Description: A list of resources without a specific type\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Double Intent\n",
      "    Source: DBLP-QuAD: A Question Answering Dataset over the DBLP Scholarly Knowledge Graph\n",
      "    Description: Includes questions that could be split into two questions\n",
      "     -------------------\n",
      "    Name: Two Intention\n",
      "    Source: LC-QuAD 2.0: A Large Dataset for Complex Question Answering over Wikidata and Dbpedia\n",
      "    Description: Questions with two separate but related intentions that could be split into two kinds of questions.\n",
      "     -------------------\n",
      "    Name: Composition\n",
      "    Source: Formulation of Research Question - Stepwise Approach\n",
      "    Description: Breaks down complex phenomena into components.\n",
      "     -------------------\n",
      "    Name: And/Or\n",
      "    Source: Ripple Down Rules for question answering\n",
      "    Description: Combine multiple questions using And or Or.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Disambiguation\n",
      "    Source: DBLP-QuAD: A Question Answering Dataset over the DBLP Scholarly Knowledge Graph\n",
      "    Description: Requires to identify the correct subject in the question.\n",
      "     -------------------\n",
      "    Name: Combine\n",
      "    Source: Ripple Down Rules for question answering\n",
      "    Description: Questions are made up of two or more independent parts that are not sharing the same terms or relations as opposed to the And/Or type.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Abbreviation\n",
      "    Source: Learning Question Classifiers\n",
      "    Description: No explanation.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Entity\n",
      "    Source: Learning Question Classifiers\n",
      "    Description: No explanation.\n",
      "     -------------------\n",
      "    Name: Entity\n",
      "    Source: Ripple Down Rules for question answering\n",
      "    Description: Categorizes questions containing noun-phrases followed up with strings such as which or what.\n",
      "     -------------------\n",
      "    Name: Entities\n",
      "    Source: Linguistically Motivated Question Classification\n",
      "    Description: Focuses on general entities, events, or object descriptions.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Description\n",
      "    Source: Learning Question Classifiers\n",
      "    Description: No explanation.\n",
      "     -------------------\n",
      "    Name: Base-Rate - Descriptive-Process\n",
      "    Source: Selecting Empirical Methods for Software Engineering Research\n",
      "    Description: Ask about describing the functionality of a process. For instance: How does X normally work? or What are the steps X goes through as it evolves?\n",
      "     -------------------\n",
      "    Name: Description and Classification\n",
      "    Source: Formulation of Research Question - Stepwise Approach\n",
      "    Description: Classifies questions that ask for descriptions or categorizations of phenomena.\n",
      "     -------------------\n",
      "    Name: Description\n",
      "    Source: Linguistically Motivated Question Classification\n",
      "    Description: Defines general descriptions of events, objects, or the purpose.\n",
      "     -------------------\n",
      "    Name: Descriptive\n",
      "    Source: Types of research questions: descriptive, predictive, or causal\n",
      "    Description: Descriptive questions seek to describe the landscape, to provide an overview of the situation. These types of questions use data to provide a quantitative summary of certain features of the world.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Human\n",
      "    Source: Learning Question Classifiers\n",
      "    Description: No explanation.\n",
      "     -------------------\n",
      "    Name: Person\n",
      "    Source: AT&T at TREC-8\n",
      "    Description: Defined as names of properties.\n",
      "     -------------------\n",
      "    Name: Social\n",
      "    Source: A Taxonomy for Classifying Questions Asked in Social Question and Answering\n",
      "    Description: The intent of a social question is to request for either companionship or coordination from others. It includes questions searching for someone who share the same agendas or someone who can provide physical or emotional assistance.\n",
      "     -------------------\n",
      "    Name: Human\n",
      "    Source: A Rule-based Question Answering System for Reading Comprehension Tests\n",
      "    Description: No further description.\n",
      "     -------------------\n",
      "    Name: Human\n",
      "    Source: Learning foci for Question Answering over Topic Maps\n",
      "    Description: No further description.\n",
      "     -------------------\n",
      "    Name: Human Description\n",
      "    Source: Linguistically Motivated Question Classification\n",
      "    Description: Focuses on general descriptions of individuals.\n",
      "     -------------------\n",
      "    Name: Answer Type - Person\n",
      "    Source: The Structure and Performance of an Open-Domain Question Answering System\n",
      "    Description: There is no further description by the authors.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Location\n",
      "    Source: Learning Question Classifiers\n",
      "    Description: No explanation.\n",
      "     -------------------\n",
      "    Name: Location\n",
      "    Source: AT&T at TREC-8\n",
      "    Description: Defined as names of properties.\n",
      "     -------------------\n",
      "    Name: Location\n",
      "    Source: A Rule-based Question Answering System for Reading Comprehension Tests\n",
      "    Description: No further description.\n",
      "     -------------------\n",
      "    Name: Location\n",
      "    Source: Linguistically Motivated Question Classification\n",
      "    Description: Focuses on questions like birthplaces, origins or general locations.\n",
      "     -------------------\n",
      "    Name: Answer Type - Location\n",
      "    Source: The Structure and Performance of an Open-Domain Question Answering System\n",
      "    Description: There is no further description by the authors.\n",
      "     -------------------\n",
      "    Name: Location\n",
      "    Source: Hybrid-SQuAD: Hybrid Scholarly Question Answering Dataset\n",
      "    Description: Answers about places.\n",
      "     -------------------\n",
      "    Name: Location\n",
      "    Source: Learning foci for Question Answering over Topic Maps\n",
      "    Description: No further description.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Numeric Value\n",
      "    Source: Learning Question Classifiers\n",
      "    Description: No explanation.\n",
      "     -------------------\n",
      "    Name: Quantity\n",
      "    Source: AT&T at TREC-8\n",
      "    Description: Defined as bare numbers\n",
      "     -------------------\n",
      "    Name: Quantification Questions\n",
      "    Source: Divide and Conquer the EmpiRE: A Community-Maintainable Knowledge Graph of Empirical Research in Requirements Engineering\n",
      "    Description: For example: How many different empirical methods are used per publication?\n",
      "     -------------------\n",
      "    Name: Numeric\n",
      "    Source: Learning foci for Question Answering over Topic Maps\n",
      "    Description: No further description.\n",
      "     -------------------\n",
      "    Name: Many\n",
      "    Source: Ripple Down Rules for question answering\n",
      "    Description: Classifies questions asking about quantities including words like \"how many\" or \"how much\".\n",
      "     -------------------\n",
      "    Name: Many-Class\n",
      "    Source: Ripple Down Rules for question answering\n",
      "    Description: Basically the same as the Many type, we assume the reason for having two categories lies in the nature of the Vietnamese language.\n",
      "     -------------------\n",
      "    Name: Answer Type - Number\n",
      "    Source: The Structure and Performance of an Open-Domain Question Answering System\n",
      "    Description: There is no further description by the authors.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: What-When\n",
      "    Source: The SciQA Scientific Question Answering Benchmark for Scholarly Knowledge\n",
      "    Description: Question starting with \"what\" and asking for \"when\".\n",
      "     -------------------\n",
      "    Name: What-Who\n",
      "    Source: The SciQA Scientific Question Answering Benchmark for Scholarly Knowledge\n",
      "    Description: Question starting with \"what\" and asking for \"who\".\n",
      "     -------------------\n",
      "    Name: WHAT\n",
      "    Source: A Rule-based Question Answering System for Reading Comprehension Tests\n",
      "    Description: Questions starting with \"What\".\n",
      "     -------------------\n",
      "    Name: What\n",
      "    Source: A Comparative Study of Question Answering over Knowledge Bases\n",
      "    Description: Questions starting with \"What\".\n",
      "     -------------------\n",
      "    Name: What\n",
      "    Source: Ripple Down Rules for question answering\n",
      "    Description: Question including the word \"What\".\n",
      "     -------------------\n",
      "    Name: What\n",
      "    Source: The Structure and Performance of an Open-Domain Question Answering System\n",
      "    Description: There is no further description by the authors. However, they also include several subtypes for this type which are: basic what, what-who, what-when, what-where\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: When\n",
      "    Source: Ripple Down Rules for question answering\n",
      "    Description: Question including the word \"When\".\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Which-Where\n",
      "    Source: The SciQA Scientific Question Answering Benchmark for Scholarly Knowledge\n",
      "    Description: Question starting with \"which\" and asking for \"where\".\n",
      "     -------------------\n",
      "    Name: WHERE\n",
      "    Source: A Rule-based Question Answering System for Reading Comprehension Tests\n",
      "    Description: Questions starting with \"Where\".\n",
      "     -------------------\n",
      "    Name: Where\n",
      "    Source: A Comparative Study of Question Answering over Knowledge Bases\n",
      "    Description: Questions starting with \"Where\".\n",
      "     -------------------\n",
      "    Name: Where\n",
      "    Source: Ripple Down Rules for question answering\n",
      "    Description: Question including the word \"Where\".\n",
      "     -------------------\n",
      "    Name: Where\n",
      "    Source: The Structure and Performance of an Open-Domain Question Answering System\n",
      "    Description: There is no further description by the authors.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Which-What\n",
      "    Source: The SciQA Scientific Question Answering Benchmark for Scholarly Knowledge\n",
      "    Description: Question starting with \"which\" and asking for \"what\".\n",
      "     -------------------\n",
      "    Name: Which\n",
      "    Source: The Structure and Performance of an Open-Domain Question Answering System\n",
      "    Description: There is no further description by the authors. However, they provide further subtypes: which-who, which-where, which-when, which-what\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Who-What\n",
      "    Source: The SciQA Scientific Question Answering Benchmark for Scholarly Knowledge\n",
      "    Description: Question starting with \"who\" and asking for \"what\".\n",
      "     -------------------\n",
      "    Name: WHO\n",
      "    Source: A Rule-based Question Answering System for Reading Comprehension Tests\n",
      "    Description: Questions starting with \"Who\".\n",
      "     -------------------\n",
      "    Name: Who\n",
      "    Source: A Comparative Study of Question Answering over Knowledge Bases\n",
      "    Description: Questions starting with \"Who\".\n",
      "     -------------------\n",
      "    Name: Who\n",
      "    Source: Ripple Down Rules for question answering\n",
      "    Description: Question including the word \"Who\".\n",
      "     -------------------\n",
      "    Name: Who\n",
      "    Source: The Structure and Performance of an Open-Domain Question Answering System\n",
      "    Description: There is no further description by the authors.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: WHY\n",
      "    Source: A Rule-based Question Answering System for Reading Comprehension Tests\n",
      "    Description: Questions starting with \"Why\".\n",
      "     -------------------\n",
      "    Name: Why\n",
      "    Source: A Comparative Study of Question Answering over Knowledge Bases\n",
      "    Description: Questions starting with \"Why\".\n",
      "     -------------------\n",
      "    Name: Why\n",
      "    Source: The Structure and Performance of an Open-Domain Question Answering System\n",
      "    Description: There is no further description by the authors.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: How\n",
      "    Source: A Comparative Study of Question Answering over Knowledge Bases\n",
      "    Description: Questions starting with \"How\".\n",
      "     -------------------\n",
      "    Name: HowWhy\n",
      "    Source: Ripple Down Rules for question answering\n",
      "    Description: Questions that contain words such as \"How\" and \"Why\".\n",
      "     -------------------\n",
      "    Name: How\n",
      "    Source: The Structure and Performance of an Open-Domain Question Answering System\n",
      "    Description: There is no further description by the authors. However, they provide further subtypes which are: basic how, how-many, how-long, how-much, how-much-<modifier>, how-far, how-tall, how-rich how-large\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Whose\n",
      "    Source: A Comparative Study of Question Answering over Knowledge Bases\n",
      "    Description: Questions starting with \"Whose\".\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Whom\n",
      "    Source: A Comparative Study of Question Answering over Knowledge Bases\n",
      "    Description: Questions starting with \"Whom\".\n",
      "     -------------------\n",
      "    Name: Whom\n",
      "    Source: The Structure and Performance of an Open-Domain Question Answering System\n",
      "    Description: There is no further description by the authors.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Orkg Content - Paper based\n",
      "    Source: The SciQA Scientific Question Answering Benchmark for Scholarly Knowledge\n",
      "    Description: Specific type of question that asks for data coming from a paper instance in the ORKG.\n",
      "     -------------------\n",
      "    Name: Orkg Content - Comparison based\n",
      "    Source: The SciQA Scientific Question Answering Benchmark for Scholarly Knowledge\n",
      "    Description: Specific type of question that asks for data coming from a comparison instance in the ORKG.\n",
      "     -------------------\n",
      "    Name: SparQL Characteristics\n",
      "    Source: The SciQA Scientific Question Answering Benchmark for Scholarly Knowledge\n",
      "    Description: This classification is used because the dataset they developed contains a query for each question to determine the answer. The first categorization is the number of triple patterns required to query the answer. The second category is the shape of the required query. The third SPARQL category is intended to provide an understanding of the complexity of the query. This is achieved by identifying the components necessary for query formulation, such as SELECT, ASK, DESCRIBE, COUNT, etc.\n",
      "     -------------------\n",
      "    Name: Number Property\n",
      "    Source: What is in the KGQA Benchmark Datasets? Survey on Challenges in Datasets for Question Answering on Knowledge Graphs\n",
      "    Description: a number resulting from a property in the SPARQL query\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Question Content - Non-Factoid - Ranking\n",
      "    Source: The SciQA Scientific Question Answering Benchmark for Scholarly Knowledge\n",
      "    Description: No further description.\n",
      "     -------------------\n",
      "    Name: Ranking\n",
      "    Source: LC-QuAD 2.0: A Large Dataset for Complex Question Answering over Wikidata and Dbpedia\n",
      "    Description: Questions that require counting facts within the graph and further aggregation of these counts.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Question Content - Non-Factoid - Temporal\n",
      "    Source: The SciQA Scientific Question Answering Benchmark for Scholarly Knowledge\n",
      "    Description: No further description.\n",
      "     -------------------\n",
      "    Name: Trends over Time\n",
      "    Source: Divide and Conquer the EmpiRE: A Community-Maintainable Knowledge Graph of Empirical Research in Requirements Engineering\n",
      "    Description: For example: How has the reporting of threats to validity evolved over time?\n",
      "     -------------------\n",
      "    Name: Temporal Aspect\n",
      "    Source: LC-QuAD 2.0: A Large Dataset for Complex Question Answering over Wikidata and Dbpedia\n",
      "    Description: Includes time requirements such as dates or timed events.\n",
      "     -------------------\n",
      "    Name: Temporal Aggregators\n",
      "    Source: 10th Question Answering over Linked Data (QALD) Challenge\n",
      "    Description: (e.g., Give me all libraries established before 1400.)\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Date\n",
      "    Source: AT&T at TREC-8\n",
      "    Description: Defined as years.\n",
      "     -------------------\n",
      "    Name: Month\n",
      "    Source: A Rule-based Question Answering System for Reading Comprehension Tests\n",
      "    Description: No further description.\n",
      "     -------------------\n",
      "    Name: Answer Type - Date\n",
      "    Source: The Structure and Performance of an Open-Domain Question Answering System\n",
      "    Description: There is no further description by the authors.\n",
      "     -------------------\n",
      "    Name: Date\n",
      "    Source: Hybrid-SQuAD: Hybrid Scholarly Question Answering Dataset\n",
      "    Description: Question that provide specific dates\n",
      "     -------------------\n",
      "    Name: Date\n",
      "    Source: What is in the KGQA Benchmark Datasets? Survey on Challenges in Datasets for Question Answering on Knowledge Graphs\n",
      "    Description: No further description.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Other Named Entity\n",
      "    Source: AT&T at TREC-8\n",
      "    Description: Not stated\n",
      "     -------------------\n",
      "    Name: Other\n",
      "    Source: Learning foci for Question Answering over Topic Maps\n",
      "    Description: No further description.\n",
      "     -------------------\n",
      "    Name: Other\n",
      "    Source: Hybrid-SQuAD: Hybrid Scholarly Question Answering Dataset\n",
      "    Description: Questions that do not fit into any of the other categories\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Answer Type - Undefined\n",
      "    Source: The Structure and Performance of an Open-Domain Question Answering System\n",
      "    Description: There is no further description by the authors.\n",
      "     -------------------\n",
      "    Name: Unknown\n",
      "    Source: What is in the KGQA Benchmark Datasets? Survey on Challenges in Datasets for Question Answering on Knowledge Graphs\n",
      "    Description: The answer type could not be detected\n",
      "     -------------------\n",
      "    Name: Miscellaneous\n",
      "    Source: AT&T at TREC-8\n",
      "    Description: Not stated\n",
      "     -------------------\n",
      "    Name: Fourth Order -Extra\n",
      "    Source: The Classification of Research Questions\n",
      "    Description: Unspecified or unclear questions\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Linear Measure\n",
      "    Source: AT&T at TREC-8\n",
      "    Description: Measure amounts such as 170 miles or 180 feet.\n",
      "     -------------------\n",
      "    Name: Answer Type - Distance\n",
      "    Source: The Structure and Performance of an Open-Domain Question Answering System\n",
      "    Description: There is no further description by the authors.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Monetary Amount\n",
      "    Source: AT&T at TREC-8\n",
      "    Description: Monetary amounts\n",
      "     -------------------\n",
      "    Name: Answer Type - Money\n",
      "    Source: The Structure and Performance of an Open-Domain Question Answering System\n",
      "    Description: There is no further description by the authors.\n",
      "     -------------------\n",
      "    Name: Answer Type - Price\n",
      "    Source: The Structure and Performance of an Open-Domain Question Answering System\n",
      "    Description: There is no further description by the authors.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Organization\n",
      "    Source: AT&T at TREC-8\n",
      "    Description: Defined as names of properties.\n",
      "     -------------------\n",
      "    Name: Human Groups\n",
      "    Source: Linguistically Motivated Question Classification\n",
      "    Description: Focuses on groups or relationships involving people, for example employees or founders.\n",
      "     -------------------\n",
      "    Name: Answer Type - Organization\n",
      "    Source: The Structure and Performance of an Open-Domain Question Answering System\n",
      "    Description: There is no further description by the authors.\n",
      "     -------------------\n",
      "    Name: Organization\n",
      "    Source: Hybrid-SQuAD: Hybrid Scholarly Question Answering Dataset\n",
      "    Description: Includes the names of Universities, research centers, or laboratories.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Duration\n",
      "    Source: AT&T at TREC-8\n",
      "    Description: Time durations such as three years, four hours and so on.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Factual Questions\n",
      "    Source: Divide and Conquer the EmpiRE: A Community-Maintainable Knowledge Graph of Empirical Research in Requirements Engineering\n",
      "    Description: For example: What types of threats to validity do the authors report?\n",
      "     -------------------\n",
      "    Name: Evidence-Based\n",
      "    Source: A Non-Factoid Question-Answering Taxonomy\n",
      "    Description: You want to learn about the features/description/definition of a concept/idea/object/event. The answer expects Wikipedia-like passage describing/defining an event/object or its properties based only on facts. Example patterns are: What is . . . ? How does/do . . . work? What are the properties of . . . ? What is the meaning of . . . ? How do you describe . . . ?\n",
      "     -------------------\n",
      "    Name: Accuracy\n",
      "    Source: A Taxonomy for Classifying Questions Asked in Social Question and Answering\n",
      "    Description: The intent of an accuracy question is to receive answers based on some factual or prescriptive knowledge. The purpose of it is to receive one or more correct answers, instead of responses based on the answerers personal experience. This type of questions usually looks for facts, definitions, and prescriptive methods on how to do something.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Method or Means of Development\n",
      "    Source: Writing good software engineering research papers\n",
      "    Description: Has an emphasis on how a software problem is solved. The focus is on methods of development or analysis that enhance productivity, quality, or automation.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Method for Analysis or Evaluation\n",
      "    Source: Writing good software engineering research papers\n",
      "    Description: Focused on methods that evaluate software approaches, tools, or technologies.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Design, Evaluation, or Analysis of a particular Instance\n",
      "    Source: Writing good software engineering research papers\n",
      "    Description: Are concerned with a certain instance that may be a particular system, practice, design or other instance of a system or method. The purpose of these questions is to evaluate or contrast the efficiency or performance of the mentioned instance or various instances.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Generalization or Characterization\n",
      "    Source: Writing good software engineering research papers\n",
      "    Description: Seek to define or understand broad concepts or systems in Software Engineering by asking for definitions, taxonomies, or general principles.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Procedure or Technique\n",
      "    Source: Writing good software engineering research papers\n",
      "    Description: Given a question, the expected result is a concept for implementation, representation, management, or analysis. The answer of a procedure or technique should be practical, providing actionable steps or new methodologies.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Instruction\n",
      "    Source: A Non-Factoid Question-Answering Taxonomy\n",
      "    Description: You want to understand the procedure/method of doing/achieving something. The expected answer structure are Instructions/guidelines provided in a step-by-step manner. Example patterns are: How to ...? How can I do . . . ? What is the process for . . . ? What is the best way to . . . ?\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Qualitative or Descriptive Model\n",
      "    Source: Writing good software engineering research papers\n",
      "    Description: Insights that provide structure or taxonomy for a given problem area. This includes architectural styles, frameworks, design patterns, non-formal domain analysis, well-grounded checklists, well-argued informal generalizations, guidance for integrating other results, and well-organized interesting observations.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Empirical Model\n",
      "    Source: Writing good software engineering research papers\n",
      "    Description: Based on observed data that often uses statistical or observational analysis to validate its conclusions.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Analytic Model\n",
      "    Source: Writing good software engineering research papers\n",
      "    Description: Formal meaning that it is often mathematically defined to allow for a formal analysis or automatic manipulation.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Tool or Notation\n",
      "    Source: Writing good software engineering research papers\n",
      "    Description: The asking point concerns a specific software tool that embodies a technique or a formal language that should have a calculus, semantics, or other basis for computing or inference.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Specific Solution, Prototype, or Judgment\n",
      "    Source: Writing good software engineering research papers\n",
      "    Description: The solution must adhere to Software Engineering principles and can take the form of a design, a prototype, or a complete implementation. The answer could also involve a thorough analysis of a system or its development.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Report\n",
      "    Source: Writing good software engineering research papers\n",
      "    Description: Interesting insights or general guidelines are provided in a report. The authors mention that the answer is not general or systematic enough to be categorized as a descriptive model.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Exploratory - Existence\n",
      "    Source: Selecting Empirical Methods for Software Engineering Research\n",
      "    Description: Explore the existence of a phenomena for example: Does X exist?\n",
      "     -------------------\n",
      "    Name: Exploratory - Description and Classification\n",
      "    Source: Selecting Empirical Methods for Software Engineering Research\n",
      "    Description: Address characteristics or classifications for instance: What are the properties of X?\n",
      "     -------------------\n",
      "    Name: Exploratory - Descriptive-Comparative\n",
      "    Source: Selecting Empirical Methods for Software Engineering Research\n",
      "    Description: Intent to investigate similarities and differences between two or more phenomena, for example: How does X differ from Y?\n",
      "     -------------------\n",
      "    Name: Research Approach - Knowledge Goal\n",
      "    Source: Construction of Design Science Research Questions\n",
      "    Description: Defines the goal of the research question. This can be exploratory, prescriptive, constructive, confirmatory, explanatory, or descriptive.\n",
      "     -------------------\n",
      "    Name: Existence\n",
      "    Source: Formulation of Research Question - Stepwise Approach\n",
      "    Description: Verifies whether a phenomenon exists or to rule out a rival explanation.\n",
      "     -------------------\n",
      "    Name: Feasibility Study or Exploration\n",
      "    Source: Writing good software engineering research papers\n",
      "    Description: Focuses on approaches that deal with a specific problem in a new way. Because these approaches address innovative or theoretical aspects, the questions ask for either an affirmative or a negative answer toward the feasibility or existence of a certain approach.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Causality - Causality\n",
      "    Source: Selecting Empirical Methods for Software Engineering Research\n",
      "    Description: Asks if one factor affects another, for example: Does X cause Y? or Does X prevent Y?.\n",
      "     -------------------\n",
      "    Name: Causality-Comparative\n",
      "    Source: Selecting Empirical Methods for Software Engineering Research\n",
      "    Description: Investigates relationships between different causes: Does X cause more Y than does Z?\n",
      "     -------------------\n",
      "    Name: Causality-Comparative Interaction\n",
      "    Source: Selecting Empirical Methods for Software Engineering Research\n",
      "    Description: Examines how context affects a cause-effect relationship.\n",
      "     -------------------\n",
      "    Name: Third Order -Contingencies\n",
      "    Source: The Classification of Research Questions\n",
      "    Description: Explores different types of relationships between phenomena. First, correlation where two phenomena are related without a clear cause. Second, conditionality where one phenomenon causes the other, or bi-conditionality where both phenomena mutually influence each other.\n",
      "     -------------------\n",
      "    Name: Causality\n",
      "    Source: Formulation of Research Question - Stepwise Approach\n",
      "    Description: Aims to investigate cause-effect relationships\n",
      "     -------------------\n",
      "    Name: Causality - Comparative interactions\n",
      "    Source: Formulation of Research Question - Stepwise Approach\n",
      "    Description: Aims to investigate interactions between variables under different conditions.\n",
      "     -------------------\n",
      "    Name: Causal\n",
      "    Source: Types of research questions: descriptive, predictive, or causal\n",
      "    Description: Causal research questions aim to find treatment targets, identify factors that increase the risk of getting a condition or injury, or estimate what will happen to people who receive one treatment compared to another.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Fact with Qualifiers\n",
      "    Source: LC-QuAD 2.0: A Large Dataset for Complex Question Answering over Wikidata and Dbpedia\n",
      "    Description: Special type related to the Wikidata KG. The term qualifiers refers to special property type used in a Wikidata graph to add further details to a triple. See: https://www.wikidata.org/wiki/Help:Qualifiers\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: String Operation\n",
      "    Source: LC-QuAD 2.0: A Large Dataset for Complex Question Answering over Wikidata and Dbpedia\n",
      "    Description: Involves performing operations on strings related to the facts of the graph, such as matching or filtering with string patterns.\n",
      "     -------------------\n",
      "    Name: String\n",
      "    Source: What is in the KGQA Benchmark Datasets? Survey on Challenges in Datasets for Question Answering on Knowledge Graphs\n",
      "    Description: Asking for string objects, such as last names or nick names\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Reason\n",
      "    Source: A Non-Factoid Question-Answering Taxonomy\n",
      "    Description: You want to find out reasons of/for something. The answer expects a list of reasons with evidence. Example patterns are: Why does . . . ? What is the reason for . . . ? What causes . . . ? How come ... happened?\n",
      "     -------------------\n",
      "    Name: Answer Type - Reason\n",
      "    Source: The Structure and Performance of an Open-Domain Question Answering System\n",
      "    Description: There is no further description by the authors.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Comparison\n",
      "    Source: A Non-Factoid Question-Answering Taxonomy\n",
      "    Description: You want to compare/contrast two or more things, understand their differences/similarities. The answer expects A list of key differences and/or similarities of something compared to another thing. Example patterns are: How is X . . . to/from Y? What are the . . . of X over Y? How does X . . . against Y?\n",
      "     -------------------\n",
      "    Name: Comparative\n",
      "    Source: 10th Question Answering over Linked Data (QALD) Challenge\n",
      "    Description: (e.g., Show me all basketball players that are higher than 2 meters.)\n",
      "     -------------------\n",
      "    Name: Second Order - Comparisons\n",
      "    Source: The Classification of Research Questions\n",
      "    Description: Deals with three types of comparative relationship. First, it addresses co-occurrence, which involves conjunction and disjunction. Then it examines equivalence and considers differences, which include disproportion and subordination.\n",
      "     -------------------\n",
      "    Name: Compare\n",
      "    Source: Ripple Down Rules for question answering\n",
      "    Description: Involves questions comparing two or more things\n",
      "     -------------------\n",
      "    Name: Descriptive - Comparative\n",
      "    Source: Formulation of Research Question - Stepwise Approach\n",
      "    Description: Flawed description, possibly because of a language barrier\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Experience\n",
      "    Source: A Non-Factoid Question-Answering Taxonomy\n",
      "    Description: You want to get advice or recommendations on a particular topic. The answer expects Advantages, disadvantages, and main features of an entity (product, event, person, etc) summarised from personal experiences. Example patterns are: Would you recommend . . . ? How do you like . . . ? What do you think about . . . ? Should I . . . ?\n",
      "     -------------------\n",
      "    Name: Knowledge\n",
      "    Source: A Taxonomy for Classifying Questions Asked in Social Question and Answering\n",
      "    Description: The intent of a knowledge question is to receive responses reflecting the answerers personal opinions, advices, preferences, or experiences. It is usually with a survey purpose, which encourages the audience to provide their personal answers.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Debate\n",
      "    Source: A Non-Factoid Question-Answering Taxonomy\n",
      "    Description: You want to debate on a hypothetical question (is someone right or wrong, is some event perceived positively or negatively?). The answer expects Arguments on a debatable topic consisting of different opinions on something supported or weakened by pros and cons of the topic in the question. Example patterns are: Does . . . exist? Can . . . be successful? Do you think . . . are . . . ? Is . . . really a . . . ?\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Aggregation\n",
      "    Source: Question Answering on Scholarly Knowledge Graphs\n",
      "    Description: Involves questions that need to aggregate information, for example, to infer the minimum, average, or most common of something.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Motivation - Problem Solving\n",
      "    Source: Construction of Design Science Research Questions\n",
      "    Description: Identifying certain kinds of problems and to build solution artifacts to address these.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Motivation - Gap Spotting\n",
      "    Source: Construction of Design Science Research Questions\n",
      "    Description: Focuses on identifying a gap in the literature and suggest an artifact to bridge it.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Motivation - Problematization\n",
      "    Source: Construction of Design Science Research Questions\n",
      "    Description: Indicates deficiencies in current theories that require additional research to address these issues.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Problem Statement\n",
      "    Source: Construction of Design Science Research Questions\n",
      "    Description: Defines the issue being addressed. This could be a research challenge, gap, problem, opportunity, or a specific requirement.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Usage of RQ\n",
      "    Source: Construction of Design Science Research Questions\n",
      "    Description: Whether a publication has used research questions at all.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Types of RQ\n",
      "    Source: Construction of Design Science Research Questions\n",
      "    Description: Categorizes broad types related to the design process, product, knowledge or other types.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Research Activities - Mode of Inquiry\n",
      "    Source: Construction of Design Science Research Questions\n",
      "    Description: Defines the activities required for the question. This can be developmental, evaluative, or a mix of both.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Theory-in-Use\n",
      "    Source: Construction of Design Science Research Questions\n",
      "    Description: Concerns theoretical statements that support the research approach. This is categorized into no specific theory, kernel theory, formal theory, or testable theory.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Outcome Artifacts\n",
      "    Source: Construction of Design Science Research Questions\n",
      "    Description: Encompasses categories such as instantiation, model, construct, and method. Additionally, it incorporates mixed categories, such as model combined with instantiation, and another combination consisting of construct, model, and instantiation.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Question Analysis/Focus\n",
      "    Source: The question answering systems: A survey\n",
      "    Description: The focus of a question has been defined by Moldovan et al. to be a word or sequence of words which indicate what information is being asked for in the question.\n",
      "     -------------------\n",
      "    Name: Focus\n",
      "    Source: The Structure and Performance of an Open-Domain Question Answering System\n",
      "    Description: There is no further description by the authors.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Question Type\n",
      "    Source: The question answering systems: A survey\n",
      "    Description: In order to correctly answer a question, it is required to understand what type of information the question asks for, because knowing the type of a question can provide constraints on what constitutes relevant data (the answer), which helps other modules to correctly locate and verify an answer.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Answer Type\n",
      "    Source: The question answering systems: A survey\n",
      "    Description: Answer type classification is a subsequent and related component to question classification. It is based on a mapping of the question classification. Once a question has been classified, a simple rule based mapping would be used to determine the potential answer types. Again, because question classification can be ambiguous, the system should allow for multiple answer types. \n",
      "     -------------------\n",
      "    Name: Answer Type\n",
      "    Source: The Structure and Performance of an Open-Domain Question Answering System\n",
      "    Description: There is no further description by the authors.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Conversational\n",
      "    Source: A Taxonomy for Classifying Questions Asked in Social Question and Answering\n",
      "    Description: The conversational tweet is usually with social or conversational purpose, and does not convey any real information need.\n",
      "     -------------------\n",
      "    Name: Zero Order\n",
      "    Source: The Classification of Research Questions\n",
      "    Description: Rhetorical Questions\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: First Order - Properties\n",
      "    Source: The Classification of Research Questions\n",
      "    Description: Describes questions that ask for the properties or characteristics that a phenomenon has\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Design\n",
      "    Source: Selecting Empirical Methods for Software Engineering Research\n",
      "    Description: Discovering improved methods for software design. For example: What is an effective way to achieve X? or What strategies help to achieve X?\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Relationship\n",
      "    Source: Formulation of Research Question - Stepwise Approach\n",
      "    Description: Examines the relationship between variables.\n",
      "     -------------------\n",
      "    Name: UnknRel\n",
      "    Source: Ripple Down Rules for question answering\n",
      "    Description: Describes questions where the relationship between things is unclear and should be provided in the answer.\n",
      "     -------------------\n",
      "    Name: Entity-relationship Questions\n",
      "    Source: Large-scale Simple Question Answering with Memory Networks\n",
      "    Description: Questions that ask for the object in a triple (subject, relationship, ?).\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Actor\n",
      "    Source: The Future of Empirical Methods in Software Engineering Research\n",
      "    Description: The Actor can be a individual, team, project, organization, or industry that performs an act.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Technology\n",
      "    Source: The Future of Empirical Methods in Software Engineering Research\n",
      "    Description: The Technology is a process model, method, technique, tool, or language that is applied on the Software System\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Activity\n",
      "    Source: The Future of Empirical Methods in Software Engineering Research\n",
      "    Description: Can be of type: plan, create, modify, or analyze.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Software System\n",
      "    Source: The Future of Empirical Methods in Software Engineering Research\n",
      "    Description: The Software System can further have classifications such as size, complexity, application domain, etc.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Time\n",
      "    Source: A Rule-based Question Answering System for Reading Comprehension Tests\n",
      "    Description: No further description.\n",
      "     -------------------\n",
      "    Name: Time\n",
      "    Source: Learning foci for Question Answering over Topic Maps\n",
      "    Description: No further description.\n",
      "     -------------------\n",
      "    Name: Time\n",
      "    Source: Linguistically Motivated Question Classification\n",
      "    Description: Focuses on time related answers like time expressions or specific dates.\n",
      "     -------------------\n",
      "    Name: Answer Type - Time\n",
      "    Source: The Structure and Performance of an Open-Domain Question Answering System\n",
      "    Description: There is no further description by the authors.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Asking Point (AP)\n",
      "    Source: Learning foci for Question Answering over Topic Maps\n",
      "    Description: When the question exactly includes the word to which the question is related.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Expected Answer Type (EAT)\n",
      "    Source: Learning foci for Question Answering over Topic Maps\n",
      "    Description: Occurs when the type of answer is implicitly given in the question, but can be inferred by understanding the syntactic and contextual cues in the question.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Definition\n",
      "    Source: Learning foci for Question Answering over Topic Maps\n",
      "    Description: No further description.\n",
      "     -------------------\n",
      "    Name: Definition\n",
      "    Source: Ripple Down Rules for question answering\n",
      "    Description: Classifies questions that are asking for a definition or explanation.\n",
      "     -------------------\n",
      "    Name: Answer Type - Definition\n",
      "    Source: The Structure and Performance of an Open-Domain Question Answering System\n",
      "    Description: There is no further description by the authors.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: request questions\n",
      "    Source: A Comparative Study of Question Answering over Knowledge Bases\n",
      "    Description: Question that ask for: Count, Provide, Give, Tell, Specify\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: UnknTerm\n",
      "    Source: Ripple Down Rules for question answering\n",
      "    Description: Defines a question where two key parts are missing. It requires to find both a relation and a term.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: ThreeTerm\n",
      "    Source: Ripple Down Rules for question answering\n",
      "    Description: Question either asks for the relation or concept\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Human Relations\n",
      "    Source: Linguistically Motivated Question Classification\n",
      "    Description: Captures relationships of people.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Multilabel\n",
      "    Source: Linguistically Motivated Question Classification\n",
      "    Description: Used for questions that can have multiple of the categories mentioned above.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Name\n",
      "    Source: The Structure and Performance of an Open-Domain Question Answering System\n",
      "    Description: There is no further description by the authors. However they provide further subtypes: name-who, name-where, name-what\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Answer Type - NNP\n",
      "    Source: The Structure and Performance of an Open-Domain Question Answering System\n",
      "    Description: There is no further description by the authors.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Answer Type - Title\n",
      "    Source: The Structure and Performance of an Open-Domain Question Answering System\n",
      "    Description: There is no further description by the authors.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Answer Type - Manner\n",
      "    Source: The Structure and Performance of an Open-Domain Question Answering System\n",
      "    Description: There is no further description by the authors.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Predictive\n",
      "    Source: Types of research questions: descriptive, predictive, or causal\n",
      "    Description: Predictive questions help readers form expectations about what is likely to happen in the future. The aim is to learn something about the future using information from the present, which requires a longitudinal study design.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Bibliometric Numbers\n",
      "    Source: Hybrid-SQuAD: Hybrid Scholarly Question Answering Dataset\n",
      "    Description: These questions typically inquire about bibliometric metrics, including publication counts, citation numbers, the h-index, and the i10-index.\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Research Works\n",
      "    Source: Hybrid-SQuAD: Hybrid Scholarly Question Answering Dataset\n",
      "    Description: Questions about research outputs and publications\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Resource Typed\n",
      "    Source: What is in the KGQA Benchmark Datasets? Survey on Challenges in Datasets for Question Answering on Knowledge Graphs\n",
      "    Description: One resource of a specific type\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Resource Untyped\n",
      "    Source: What is in the KGQA Benchmark Datasets? Survey on Challenges in Datasets for Question Answering on Knowledge Graphs\n",
      "    Description: One resource without a specific type\n",
      "______________________\n",
      "     -------------------\n",
      "    Name: Clause\n",
      "    Source: Ripple Down Rules for question answering\n",
      "    Description: Defines questions where one part depends on another.\n"
     ]
    }
   ],
   "source": [
    "type_descriptions = {}\n",
    "\n",
    "for paper in extraction_mapping:\n",
    "    paper_title = paper.get(\"title\", \"No title\")\n",
    "    for type_dict in paper.get(\"types\", []):\n",
    "        the_type = type_dict.get(\"type\", \"unknown\")\n",
    "        description = type_dict.get(\"description\", \"No description\")\n",
    "        type_descriptions[(paper_title, the_type)] = description\n",
    "\n",
    "\n",
    "clusters_with_descriptions = []\n",
    "\n",
    "for iteration in cluster_increments:\n",
    "    iteration_count = iteration.get(\"iteration\", -1)\n",
    "    if iteration_count != 1:\n",
    "        continue\n",
    "\n",
    "    for cluster in iteration.get(\"clusters\", []):\n",
    "        cluster_data = []\n",
    "        print(\"______________________\")\n",
    "        for item in cluster.get(\"types\", []):\n",
    "            print(\"     -------------------\")\n",
    "            name = item.get(\"name\", \"unknown\")\n",
    "            source = item.get(\"source\", \"unknown\")\n",
    "            description = type_descriptions.get((source, name), \"No Mapping Found\")\n",
    "            print(f\"    Name: {name}\")\n",
    "            print(f\"    Source: {source}\")\n",
    "            print(f\"    Description: {description}\")\n",
    "            if description == \"No Mapping Found\":\n",
    "                print(f\"No mapping found for {source} - {name}\")\n",
    "            cluster_data.append({\"name\": name, \"source\": source, \"description\": description})\n",
    "        \n",
    "        clusters_with_descriptions.append({\n",
    "            \"cluster_types_with_description\": cluster_data,\n",
    "        })        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Iteration 2 - Clusters with Description and Parent Clusters\n",
    "\n",
    "In the following output, the clusters of the second iteration are shown with their respective types, descriptions, and parent clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________\n",
      "Cluster ID: 1000\n",
      "Cluster Name: Knowledge Graph Representation | Knowledge Graph Organization | Fact Granularity\n",
      "Cluster info: Groups those clusters that describe how the data that is asked for is organized in the Knowledge Graph. It distinguishes between the amount of facts that are needed to answer a question.\n",
      "Subclusters: 2: \n",
      "     Subcluster ID: 1\n",
      "     Name: Single Fact\n",
      "     Info: Classifies questions that can be fully answered by retrieving a single fact from the Knowledge Graph.\n",
      "     -------------------\n",
      "     Subcluster ID: 2\n",
      "     Name: Multi Fact\n",
      "     Info: Classifies questions that require multiple facts to be retrieved from the Knowledge Graph to be fully answered.\n",
      "     -------------------\n",
      "______________________\n",
      "Cluster ID: 1001\n",
      "Cluster Name: Answer Type | Answer Output Types & Formats\n",
      "Cluster info: Defines the expected answer format or data type. As such it classifies what the question expect to be in the answer.\n",
      "Subclusters: 33: \n",
      "     Subcluster ID: 3\n",
      "     Name: Generic Answer Type\n",
      "     Info: Generically defines the expected answer type.\n",
      "     -------------------\n",
      "     Subcluster ID: 4\n",
      "     Name: Undefined\n",
      "     Info: Groups questions for which the expected answer type is unclear or cannot be determined by standard classification rules.\n",
      "     -------------------\n",
      "     Subcluster ID: 5\n",
      "     Name: Date\n",
      "     Info: Classifies questions that expect a date as an answer.\n",
      "     -------------------\n",
      "     Subcluster ID: 6\n",
      "     Name: Other\n",
      "     Info: Classifies those questions that expect an answer type that does not fit in any of the other categories.\n",
      "     -------------------\n",
      "     Subcluster ID: 7\n",
      "     Name: Distance Measurement\n",
      "     Info: Classifies answers that expect a linear measure such as distance or length\n",
      "     -------------------\n",
      "     Subcluster ID: 8\n",
      "     Name: Actor\n",
      "     Info: Identifies questions that ask for an actor which is a individual, team, project, organization, or industry that performs an act.\n",
      "     -------------------\n",
      "     Subcluster ID: 9\n",
      "     Name: Technology\n",
      "     Info: Classifies questions where the answer should be a technology which can be a process model, method, technique, tool, or language that is applied on the Software System\n",
      "     -------------------\n",
      "     Subcluster ID: 10\n",
      "     Name: Expected Answer Type (EAT)\n",
      "     Info: Relates to questions where the expected answer type is not explicitly given in the question but must be inferred from the context.\n",
      "     -------------------\n",
      "     Subcluster ID: 11\n",
      "     Name: Asking Point Given\n",
      "     Info: Specifies those questions where the asking point is directly included in the question.\n",
      "     -------------------\n",
      "     Subcluster ID: 12\n",
      "     Name: Definition\n",
      "     Info: Classifies questions that expect a definition or explanation, where the answer provides a clear definition or description of a concept.\n",
      "     -------------------\n",
      "     Subcluster ID: 13\n",
      "     Name: Time\n",
      "     Info: Classifies those questions that ask for a time.\n",
      "     -------------------\n",
      "     Subcluster ID: 14\n",
      "     Name: Name\n",
      "     Info: Focuses on answers that ask for names (or named entities) like persons, locations, or objects.\n",
      "     -------------------\n",
      "     Subcluster ID: 15\n",
      "     Name: Title\n",
      "     Info: Covers answer types where the answer is expected to be a title such as the title of a publication or work.\n",
      "     -------------------\n",
      "     Subcluster ID: 16\n",
      "     Name: Bibliometric Numbers\n",
      "     Info: Specifies answers that involve bibliometric data such as publication counts, citation numbers, h-index, or i10-index.\n",
      "     -------------------\n",
      "     Subcluster ID: 17\n",
      "     Name: Manner\n",
      "     Info: Used when the answer is expected to detail the manner by which an action is performed.\n",
      "     -------------------\n",
      "     Subcluster ID: 18\n",
      "     Name: Software System\n",
      "     Info: Classifies answers that describe features of a software system, such as its size, complexity, or application domain.\n",
      "     -------------------\n",
      "     Subcluster ID: 19\n",
      "     Name: Monetary\n",
      "     Info: Classifies questions that expect a monetary amount as an answer.\n",
      "     -------------------\n",
      "     Subcluster ID: 20\n",
      "     Name: Abbreviation\n",
      "     Info: Classifies questions that expect the long or short form of an abbreviation as an answer.\n",
      "     -------------------\n",
      "     Subcluster ID: 97\n",
      "     Name: Procedure/Technique\n",
      "     Info: Given a question, the expected result is a concept for implementation, representation, management, or analysis.\n",
      "     -------------------\n",
      "     Subcluster ID: 21\n",
      "     Name: Instructional\n",
      "     Info: Covers those questions that expect as answer step-by-step procedures, instructions, or techniques to achieve a specified task.\n",
      "     -------------------\n",
      "     Subcluster ID: 22\n",
      "     Name: Organization\n",
      "     Info: Groups answers that identify organizations or human groups, including universities, research centers, laboratories, and other entities.\n",
      "     -------------------\n",
      "     Subcluster ID: 23\n",
      "     Name: Duration\n",
      "     Info: Covers answers that express time durations such as 'three years' or 'few hours'.\n",
      "     -------------------\n",
      "     Subcluster ID: 24\n",
      "     Name: Boolean\n",
      "     Info: Classifies questions that expect an affirmative or negative response.\n",
      "     -------------------\n",
      "     Subcluster ID: 25\n",
      "     Name: Entity\n",
      "     Info: Used for questions where the answer is expected to name one or more entities or objects identified within the question.\n",
      "     -------------------\n",
      "     Subcluster ID: 26\n",
      "     Name: Description\n",
      "     Info: Focuses on answers that provide descriptions, classifications, or overviews of processes or phenomena.\n",
      "     -------------------\n",
      "     Subcluster ID: 27\n",
      "     Name: Properties\n",
      "     Info: Classifies answers that list or detail the properties or characteristics inherent to a phenomenon or entity.\n",
      "     -------------------\n",
      "     Subcluster ID: 28\n",
      "     Name: Human/Person\n",
      "     Info: Covers answers that refer to human subjects\n",
      "     -------------------\n",
      "     Subcluster ID: 29\n",
      "     Name: Location\n",
      "     Info: Specifies answers that are geographic in nature.\n",
      "     -------------------\n",
      "     Subcluster ID: 30\n",
      "     Name: Quantitative\n",
      "     Info: Groups answers that provide numerical information, counts, or quantitative measures.\n",
      "     -------------------\n",
      "     Subcluster ID: 31\n",
      "     Name: Tool/Notation\n",
      "     Info: The question asks for a specific software tool that embodies a technique or a formal language that should have a calculus, semantics, or other basis for computing or inference.\n",
      "     -------------------\n",
      "     Subcluster ID: 32\n",
      "     Name: Solution\n",
      "     Info: The question asks for a specific solution, design prototype, or evaluative judgment based on established software engineering principles.\n",
      "     -------------------\n",
      "     Subcluster ID: 33\n",
      "     Name: Report\n",
      "     Info: Interesting insights or general guidelines are provided in a report. The authors mention that the answer is not general or systematic enough to be categorized as a descriptive model.\n",
      "     -------------------\n",
      "     Subcluster ID: 35\n",
      "     Name: Theoretical Framework\n",
      "     Info: Questions that ask for theoretical statements that support a research approach. This is categorized into no specific theory, kernel theory, formal theory, or testable theory.\n",
      "     -------------------\n",
      "______________________\n",
      "Cluster ID: 1003\n",
      "Cluster Name: Question Type | Information Retrieval Actions | Question Processing Steps | Retrieval Operations\n",
      "Cluster info: Includes those clusters that indicate what activities are required from the retriever to be performed to arrive at the answer. As such it specifies the retrieval operations and query-processing steps required to derive an answer\n",
      "Subclusters: 18: \n",
      "     Subcluster ID: 36\n",
      "     Name: Question Type\n",
      "     Info: Generically defines the type of information request\n",
      "     -------------------\n",
      "     Subcluster ID: 37\n",
      "     Name: Activity\n",
      "     Info: Generically defines the acitivies that are required to be performed to arrive at the answer.\n",
      "     -------------------\n",
      "     Subcluster ID: 38\n",
      "     Name: Negation\n",
      "     Info: Expects the retrieval process to include negations.\n",
      "     -------------------\n",
      "     Subcluster ID: 39\n",
      "     Name: Clause\n",
      "     Info: Defines questions where one part depends on another.\n",
      "     -------------------\n",
      "     Subcluster ID: 40\n",
      "     Name: Contingencies\n",
      "     Info: Groups questions that involve cause effect relationships. It involves correlations but also causal relationships.\n",
      "     -------------------\n",
      "     Subcluster ID: 41\n",
      "     Name: Double Negation\n",
      "     Info: Requires to dobule negate parts of the query to arrive at the answer.\n",
      "     -------------------\n",
      "     Subcluster ID: 42\n",
      "     Name: Counts\n",
      "     Info: Classifies questions that require to count information.\n",
      "     -------------------\n",
      "     Subcluster ID: 43\n",
      "     Name: Request\n",
      "     Info: Generically classifies questions by the task that is specifically states like 'give' or 'list'\n",
      "     -------------------\n",
      "     Subcluster ID: 44\n",
      "     Name: Superlatives\n",
      "     Info: Groups questions asking for extreme values (maximum/minimum).\n",
      "     -------------------\n",
      "     Subcluster ID: 45\n",
      "     Name: Comparison\n",
      "     Info: Classifies questions that compare two or more entities by extracting their similarities or differences\n",
      "     -------------------\n",
      "     Subcluster ID: 46\n",
      "     Name: Listing\n",
      "     Info: Classifies questions that require to retrieve multiple properties about a phenomenon and list them.\n",
      "     -------------------\n",
      "     Subcluster ID: 47\n",
      "     Name: String Operation\n",
      "     Info: Specifies questions that demand operations on string data\n",
      "     -------------------\n",
      "     Subcluster ID: 48\n",
      "     Name: Multiple Intents\n",
      "     Info: Classifies questions that have multiple intentions which could be broken up into multiple different questions\n",
      "     -------------------\n",
      "     Subcluster ID: 49\n",
      "     Name: Disambiguation\n",
      "     Info: Focuses on the activity of resolving ambiguity in questions by identifying the correct subject or term among several possibilities before retrieval.\n",
      "     -------------------\n",
      "     Subcluster ID: 50\n",
      "     Name: Ranking\n",
      "     Info: Classifies questions that not only count or list facts but also rank or order them\n",
      "     -------------------\n",
      "     Subcluster ID: 51\n",
      "     Name: Temporal\n",
      "     Info: Classifies questions that that involve time series or trends over time, incorporating temporal aggregators and aspects into the retrieval process.\n",
      "     -------------------\n",
      "     Subcluster ID: 52\n",
      "     Name: Aggregation\n",
      "     Info: Focuses on queries that require aggregation functions (such as average, sum, or grouping) to synthesize data into a meaningful answer.\n",
      "     -------------------\n",
      "     Subcluster ID: 53\n",
      "     Name: Relationship\n",
      "     Info: Targets questions that ask for the relationship between entities by identifying the connecting predicates or relationships in the knowledge graph.\n",
      "     -------------------\n",
      "______________________\n",
      "Cluster ID: 1004\n",
      "Cluster Name: WH-Patterns\n",
      "Cluster info: Groups questions by their interrogative form (Wh-questions), distinguishing between different wh-word patterns.\n",
      "Subclusters: 9: \n",
      "     Subcluster ID: 54\n",
      "     Name: What\n",
      "     Info: Classifies questions that begin with 'What'.\n",
      "     -------------------\n",
      "     Subcluster ID: 55\n",
      "     Name: Where\n",
      "     Info: Classifies questions that begin with 'Where'.\n",
      "     -------------------\n",
      "     Subcluster ID: 56\n",
      "     Name: Which\n",
      "     Info: Classifies questions that begin with 'Which'.\n",
      "     -------------------\n",
      "     Subcluster ID: 57\n",
      "     Name: When\n",
      "     Info: Classifies questions that begin with 'When'.\n",
      "     -------------------\n",
      "     Subcluster ID: 58\n",
      "     Name: Who\n",
      "     Info: Classifies questions that begin with 'Who'.\n",
      "     -------------------\n",
      "     Subcluster ID: 59\n",
      "     Name: Why\n",
      "     Info: Classifies questions that begin with 'Why'.\n",
      "     -------------------\n",
      "     Subcluster ID: 60\n",
      "     Name: How\n",
      "     Info: Classifies questions that begin with 'How'.\n",
      "     -------------------\n",
      "     Subcluster ID: 61\n",
      "     Name: Whose\n",
      "     Info: Classifies questions that begin with 'Whose'.\n",
      "     -------------------\n",
      "     Subcluster ID: 62\n",
      "     Name: Whom\n",
      "     Info: Classifies questions that begin with 'Whom'.\n",
      "     -------------------\n",
      "______________________\n",
      "Cluster ID: 1005\n",
      "Cluster Name: Specialized Knowledge Base Types\n",
      "Cluster info: Contains classifications specific to querying specialized knowledge bases. Therefore to apply these classifications, it is required to run the question on that specific knowledge base.\n",
      "Subclusters: 2: \n",
      "     Subcluster ID: 63\n",
      "     Name: ORKG and SPARQL Queries\n",
      "     Info: Classifies questions specific to the ORKG, including those about paperbased content, comparison instances, and the complexity of underlying SPARQL query structures.\n",
      "     -------------------\n",
      "     Subcluster ID: 64\n",
      "     Name: Wikidata Qualifiers\n",
      "     Info: Specifies questions that require answers including qualifiers (which are additional detail properties in Wikidata) to enrich the retrieved fact.\n",
      "     -------------------\n",
      "______________________\n",
      "Cluster ID: 1006\n",
      "Cluster Name: Research-Orientation | Research-Focus | Scholarly Question Type\n",
      "Cluster info: Focuses on scholarly and research-oriented questions\n",
      "Subclusters: 8: \n",
      "     Subcluster ID: 65\n",
      "     Name: Research Output\n",
      "     Info: Classifies questions focused on research outputs from publications\n",
      "     -------------------\n",
      "     Subcluster ID: 66\n",
      "     Name: Development Methods\n",
      "     Info: Covers questions that request details on the methods, processes, or procedures used to develop software solutions, including aspects such as design patterns, best practices, and algorithmic strategies.\n",
      "     -------------------\n",
      "     Subcluster ID: 67\n",
      "     Name: Analytical Methods\n",
      "     Info: Covers questions that seek details on strategies, techniques, or frameworks used for analyzing or evaluating software tools, technologies, or approaches.\n",
      "     -------------------\n",
      "     Subcluster ID: 68\n",
      "     Name: Instance-Specific\n",
      "     Info: The same as 'Development Methods' but specific to a particular instance.\n",
      "     -------------------\n",
      "     Subcluster ID: 69\n",
      "     Name: Generalization \n",
      "     Info: Classifies questions that seek broad concepts, taxonomies, or general principles in software engineering.\n",
      "     -------------------\n",
      "     Subcluster ID: 70\n",
      "     Name: Qualitative Modeling\n",
      "     Info: Groups questions expecting qualitative models which covers a wide variety of different types of models, including structures or taxonomies, architecture designs, frameworks, design patterns, and other non quantitative results. \n",
      "     -------------------\n",
      "     Subcluster ID: 71\n",
      "     Name: Empirical Modeling\n",
      "     Info: Classifies questions that ask for predictive models based on observed data.\n",
      "     -------------------\n",
      "     Subcluster ID: 72\n",
      "     Name: Analytic Modeling\n",
      "     Info: Focuses on questions expecting formal, mathematically defined models to facilitate analysis or computation.\n",
      "     -------------------\n",
      "______________________\n",
      "Cluster ID: 1007\n",
      "Cluster Name: Answer Credibility | Answer Reliability\n",
      "Cluster info: Classifies questions by the credibility of the answer with regard to the truthfulness.\n",
      "Subclusters: 5: \n",
      "     Subcluster ID: 73\n",
      "     Name: Factual\n",
      "     Info: Groups questions that expect factual, evidence-based answers.\n",
      "     -------------------\n",
      "     Subcluster ID: 74\n",
      "     Name: Opinion\n",
      "     Info: Covers questions where the answer is expected to reflect personal experiences, opinions, or recommendations rather than strict facts.\n",
      "     -------------------\n",
      "     Subcluster ID: 75\n",
      "     Name: Debate\n",
      "     Info: Classifies questions that intend to provoke discussion or argumentation rather than factual answers.\n",
      "     -------------------\n",
      "     Subcluster ID: 76\n",
      "     Name: Conversational\n",
      "     Info: Identifies questions that are rhetorical or conversational in nature, where a definitive factual answer is not required.\n",
      "     -------------------\n",
      "     Subcluster ID: 77\n",
      "     Name: Predictive\n",
      "     Info: Focuses on questions that ask for predictions or forecasts.\n",
      "     -------------------\n",
      "______________________\n",
      "Cluster ID: 1008\n",
      "Cluster Name: Question Goal | Question Intent | Question Objective\n",
      "Cluster info: Defines the overall goal or intent behind a question.\n",
      "Subclusters: 7: \n",
      "     Subcluster ID: 78\n",
      "     Name: Exploratory\n",
      "     Info: Classifies questions aimed at exploring the existence, description, or comparative features of a phenomenon.\n",
      "     -------------------\n",
      "     Subcluster ID: 79\n",
      "     Name: Reasoning\n",
      "     Info: Classifies questions that seek reasons or causes behind events or phenomena.\n",
      "     -------------------\n",
      "     Subcluster ID: 80\n",
      "     Name: Problem Solving\n",
      "     Info: Focuses on questions that seek to find solutions or resolve issues.\n",
      "     -------------------\n",
      "     Subcluster ID: 81\n",
      "     Name: Gap Spotting\n",
      "     Info: Classifies questions that aim to spot gaps in existing literature or research, thereby highlighting areas needing further investigation.\n",
      "     -------------------\n",
      "     Subcluster ID: 82\n",
      "     Name: Problematization\n",
      "     Info: Classifies questions that aim to articulate deficiencies or problems in current theories and practices suggesting a need for additional research.\n",
      "     -------------------\n",
      "     Subcluster ID: 83\n",
      "     Name: Focus\n",
      "     Info: Generally defines the aim of a question as the focus, which should guide the extraction of most relevant information from the Knowledge Graph\n",
      "     -------------------\n",
      "     Subcluster ID: 84\n",
      "     Name: Design\n",
      "     Info: Discovering improved methods for software design.\n",
      "     -------------------\n",
      "______________________\n",
      "Cluster ID: 1009\n",
      "Cluster Name: Application-Specific\n",
      "Cluster info: Groups those clusters where the type is specific to an application or use case and not useful for our task.\n",
      "Subclusters: 12: \n",
      "     Subcluster ID: 85\n",
      "     Name: Problem Statement Identification\n",
      "     Info: Defines the issue being addressed. This could be a research challenge, gap, problem, opportunity, or a specific requirement.\n",
      "     -------------------\n",
      "     Subcluster ID: 86\n",
      "     Name: Research Question Utilization\n",
      "     Info: Whether a publication has used research questions at all.\n",
      "     -------------------\n",
      "     Subcluster ID: 87\n",
      "     Name: Research Question Typology\n",
      "     Info: Categorizes broad types related to the design process, product, knowledge or other types.\n",
      "     -------------------\n",
      "     Subcluster ID: 88\n",
      "     Name: Inquiry Mode Classification\n",
      "     Info: Defines the activities required for the question. This can be developmental, evaluative, or a mix of both.\n",
      "     -------------------\n",
      "     Subcluster ID: 89\n",
      "     Name: Outcome Artifact Classification\n",
      "     Info: Encompasses categories such as instantiation, model, construct, and method. Additionally, it incorporates mixed categories, such as model combined with instantiation, and another combination consisting of construct, model, and instantiation.\n",
      "     -------------------\n",
      "     Subcluster ID: 90\n",
      "     Name: Missing Term Resolution\n",
      "     Info: Defines a question where two key parts are missing. It requires to find both a relation and a term.\n",
      "     -------------------\n",
      "     Subcluster ID: 91\n",
      "     Name: Three Term Resolution\n",
      "     Info: Question either asks for the relation or concept\n",
      "     -------------------\n",
      "     Subcluster ID: 92\n",
      "     Name: Human Relationship Inquiry\n",
      "     Info: Focuses on questions that capture relationships between people\n",
      "     -------------------\n",
      "     Subcluster ID: 93\n",
      "     Name: Multi Category Classification\n",
      "     Info: General type for question that span multiple categories simultaneously\n",
      "     -------------------\n",
      "     Subcluster ID: 94\n",
      "     Name: NNP Answer Type\n",
      "     Info: Uknown what this type is used for\n",
      "     -------------------\n",
      "     Subcluster ID: 95\n",
      "     Name: Resource Typed\n",
      "     Info: Classifies questions that expect a single resource of a specific, predefined type as the answer.\n",
      "     -------------------\n",
      "     Subcluster ID: 96\n",
      "     Name: Resource Untyped\n",
      "     Info: Specifies questions that expect an answer in the form of a resource without any explicit type classification.\n",
      "     -------------------\n",
      "Amount of clusters: 9\n"
     ]
    }
   ],
   "source": [
    "type_descriptions = {}\n",
    "for paper in extraction_mapping:\n",
    "    paper_title = paper.get(\"title\", \"No title\")\n",
    "    for type_dict in paper.get(\"types\", []):\n",
    "        the_type = type_dict.get(\"type\", \"unknown\")\n",
    "        description = type_dict.get(\"description\", \"No description\")\n",
    "        type_descriptions[(paper_title, the_type)] = description\n",
    "\n",
    "\n",
    "grouped_clusters_with_description = []\n",
    "amount_of_clusters = 0\n",
    "for iteration in cluster_increments:\n",
    "    iteration_count = iteration.get(\"iteration\", -1)\n",
    "    if iteration_count != 2:\n",
    "        continue\n",
    "    \n",
    "    for cluster in iteration.get(\"clusters\", []):\n",
    "        cluster_info = cluster.get(\"info\", \"No info\")\n",
    "        print(\"______________________\")\n",
    "        print(f\"Cluster ID: {cluster.get('id', 'unknown')}\")\n",
    "        print(f\"Cluster Name: {cluster.get('name', 'unknown')}\")\n",
    "        print(f\"Cluster info: {cluster_info}\")\n",
    "        print(f\"Subclusters: {len(cluster.get('subclusters', []))}: \")\n",
    "        subcluster_data = []\n",
    "        for index, subcluster in enumerate(cluster.get(\"subclusters\", [])):\n",
    "            subcluster_name = subcluster.get(\"name\", \"unknown\")\n",
    "            subcluster_info = subcluster.get(\"info\", \"No info\")\n",
    "            subcluster_id = subcluster.get(\"id\", \"unknown\")\n",
    "            print(f\"     Subcluster ID: {subcluster_id}\")\n",
    "            print(f\"     Name: {subcluster_name}\")\n",
    "            print(f\"     Info: {subcluster_info}\")\n",
    "            print(\"     -------------------\")\n",
    "            cluster_data = []\n",
    "\n",
    "            for item in subcluster.get(\"types\", []):\n",
    "                name = item.get(\"name\", \"unknown\")\n",
    "                source = item.get(\"source\", \"unknown\")\n",
    "                description = type_descriptions.get((source, name), \"No Mapping Found\")\n",
    "                if description == \"No Mapping Found\":\n",
    "                    print(f\"No mapping found for {source} - {name}\")\n",
    "                cluster_data.append({\"name\": name, \"source\": source, \"description\": description})\n",
    "            subcluster_data.append({\n",
    "                \"cluster_types_with_description\": cluster_data,\n",
    "                \"subcluster_id\": subcluster_id,\n",
    "                \"subcluster_name\": subcluster_name,\n",
    "                \"subcluster_info\": subcluster_info,\n",
    "            })\n",
    "            \n",
    "        grouped_clusters_with_description.append(subcluster_data)\n",
    "print(f\"Amount of clusters: {len(grouped_clusters_with_description)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Analysis of Clusters\n",
    "\n",
    "In the following output, a total summary analysis is shown, including the number of clusters, types, and descriptions. The analysis also includes the number of clusters per type and the number of clusters per parent cluster.\n",
    "It allows to get a better understanding of where each cluster originates from and what their characteristics are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________\n",
      "Parent-Cluster ID: 1000\n",
      "Parent-Cluster Name: Knowledge Graph Representation | Knowledge Graph Organization | Fact Granularity\n",
      "Parent-Cluster Info: Groups those clusters that describe how the data that is asked for is organized in the Knowledge Graph. It distinguishes between the amount of facts that are needed to answer a question.\n",
      "Amount of subclusters: 2\n",
      "Amount of types in all subclusters: 11\n",
      "Amount of different domains: 3\n",
      "Amount of different years: 5\n",
      "Amount of different categories: 2\n",
      "Amount of different sources: 6\n",
      "Names of Subclusters: ['Single Fact', 'Multi Fact']\n",
      "Domains: 3x Scholarly, 2x General, 1x Vietnamese Language\n",
      "Years: 2x 2023, 1x 2019, 1x 2020, 1x 2015, 1x 2017\n",
      "Categories: 5x Knowledge Graph Question Answering Dataset, 1x Question Classifier\n",
      "Sources:  ['DBLP-QuAD: A Question Answering Dataset over the DBLP Scholarly Knowledge Graph', 'The SciQA Scientific Question Answering Benchmark for Scholarly Knowledge', 'LC-QuAD 2.0: A Large Dataset for Complex Question Answering over Wikidata and Dbpedia', 'Question Answering on Scholarly Knowledge Graphs', 'Large-scale Simple Question Answering with Memory Networks', 'Ripple Down Rules for question answering']\n",
      "______________________\n",
      "Parent-Cluster ID: 1001\n",
      "Parent-Cluster Name: Answer Type | Answer Output Types & Formats\n",
      "Parent-Cluster Info: Defines the expected answer format or data type. As such it classifies what the question expect to be in the answer.\n",
      "Amount of subclusters: 33\n",
      "Amount of types in all subclusters: 87\n",
      "Amount of different domains: 10\n",
      "Amount of different years: 17\n",
      "Amount of different categories: 4\n",
      "Amount of different sources: 25\n",
      "Names of Subclusters: ['Generic Answer Type', 'Undefined', 'Date', 'Other', 'Distance Measurement', 'Actor', 'Technology', 'Expected Answer Type (EAT)', 'Asking Point Given', 'Definition', 'Time', 'Name', 'Title', 'Bibliometric Numbers', 'Manner', 'Software System', 'Monetary', 'Abbreviation', 'Procedure/Technique', 'Instructional', 'Organization', 'Duration', 'Boolean', 'Entity', 'Description', 'Properties', 'Human/Person', 'Location', 'Quantitative', 'Tool/Notation', 'Solution', 'Report', 'Theoretical Framework']\n",
      "Domains: 11x General, 4x Scholarly, 3x Software Engineering, 1x Vietnamese Language, 1x Spoken Natural Language Processing, 1x Covid, 1x Healthcare, 1x Social Science, 1x Requirements Engineering, 1x Design Science\n",
      "Years: 1x 2016, 2x 2000, 1x 2021, 1x 1999, 1x 1984, 1x 2024, 1x 2009, 1x 2007, 1x 2017, 2x 2015, 1x 2002, 1x 2003, 2x 2022, 3x 2023, 3x 2019, 2x 2020, 1x 2008\n",
      "Categories: 9x Question Classifier, 8x Knowledge Graph Question Answering Dataset, 6x Research Questions, 2x Other\n",
      "Sources:  ['The question answering systems: A survey', 'The Structure and Performance of an Open-Domain Question Answering System', 'What is in the KGQA Benchmark Datasets? Survey on Challenges in Datasets for Question Answering on Knowledge Graphs', 'AT&T at TREC-8', 'The Classification of Research Questions', 'A Rule-based Question Answering System for Reading Comprehension Tests', 'Hybrid-SQuAD: Hybrid Scholarly Question Answering Dataset', 'Learning foci for Question Answering over Topic Maps', 'The Future of Empirical Methods in Software Engineering Research', 'Ripple Down Rules for question answering', 'Linguistically Motivated Question Classification', 'Learning Question Classifiers', 'Writing good software engineering research papers', 'A Non-Factoid Question-Answering Taxonomy', 'DBLP-QuAD: A Question Answering Dataset over the DBLP Scholarly Knowledge Graph', 'The SciQA Scientific Question Answering Benchmark for Scholarly Knowledge', 'LC-QuAD 2.0: A Large Dataset for Complex Question Answering over Wikidata and Dbpedia', 'Question Answering on Scholarly Knowledge Graphs', 'A Comparative Study of Question Answering over Knowledge Bases', 'Selecting Empirical Methods for Software Engineering Research', 'Formulation of Research Question - Stepwise Approach', 'Types of research questions: descriptive, predictive, or causal', 'A Taxonomy for Classifying Questions Asked in Social Question and Answering', 'Divide and Conquer the EmpiRE: A Community-Maintainable Knowledge Graph of Empirical Research in Requirements Engineering', 'Construction of Design Science Research Questions']\n",
      "______________________\n",
      "Parent-Cluster ID: 1003\n",
      "Parent-Cluster Name: Question Type | Information Retrieval Actions | Question Processing Steps | Retrieval Operations\n",
      "Parent-Cluster Info: Includes those clusters that indicate what activities are required from the retriever to be performed to arrive at the answer. As such it specifies the retrieval operations and query-processing steps required to derive an answer\n",
      "Amount of subclusters: 18\n",
      "Amount of types in all subclusters: 53\n",
      "Amount of different domains: 7\n",
      "Amount of different years: 11\n",
      "Amount of different categories: 4\n",
      "Amount of different sources: 17\n",
      "Names of Subclusters: ['Question Type', 'Activity', 'Negation', 'Clause', 'Contingencies', 'Double Negation', 'Counts', 'Request', 'Superlatives', 'Comparison', 'Listing', 'String Operation', 'Multiple Intents', 'Disambiguation', 'Ranking', 'Temporal', 'Aggregation', 'Relationship']\n",
      "Domains: 8x General, 2x Software Engineering, 3x Scholarly, 1x Vietnamese Language, 1x Healthcare, 1x Covid, 1x Requirements Engineering\n",
      "Years: 1x 2016, 1x 2007, 4x 2023, 1x 2017, 1x 2008, 1x 1984, 2x 2019, 2x 2020, 1x 2021, 2x 2022, 1x 2015\n",
      "Categories: 3x Question Classifier, 1x Other, 9x Knowledge Graph Question Answering Dataset, 4x Research Questions\n",
      "Sources:  ['The question answering systems: A survey', 'The Future of Empirical Methods in Software Engineering Research', 'DBLP-QuAD: A Question Answering Dataset over the DBLP Scholarly Knowledge Graph', 'The SciQA Scientific Question Answering Benchmark for Scholarly Knowledge', 'Ripple Down Rules for question answering', 'Selecting Empirical Methods for Software Engineering Research', 'The Classification of Research Questions', 'Formulation of Research Question - Stepwise Approach', 'Types of research questions: descriptive, predictive, or causal', 'LC-QuAD 2.0: A Large Dataset for Complex Question Answering over Wikidata and Dbpedia', '10th Question Answering over Linked Data (QALD) Challenge', 'What is in the KGQA Benchmark Datasets? Survey on Challenges in Datasets for Question Answering on Knowledge Graphs', 'A Comparative Study of Question Answering over Knowledge Bases', 'A Non-Factoid Question-Answering Taxonomy', 'Question Answering on Scholarly Knowledge Graphs', 'Large-scale Simple Question Answering with Memory Networks', 'Divide and Conquer the EmpiRE: A Community-Maintainable Knowledge Graph of Empirical Research in Requirements Engineering']\n",
      "______________________\n",
      "Parent-Cluster ID: 1004\n",
      "Parent-Cluster Name: WH-Patterns\n",
      "Parent-Cluster Info: Groups questions by their interrogative form (Wh-questions), distinguishing between different wh-word patterns.\n",
      "Amount of subclusters: 9\n",
      "Amount of types in all subclusters: 28\n",
      "Amount of different domains: 4\n",
      "Amount of different years: 4\n",
      "Amount of different categories: 2\n",
      "Amount of different sources: 5\n",
      "Names of Subclusters: ['What', 'Where', 'Which', 'When', 'Who', 'Why', 'How', 'Whose', 'Whom']\n",
      "Domains: 1x Scholarly, 2x General, 1x Covid, 1x Vietnamese Language\n",
      "Years: 1x 2023, 2x 2000, 1x 2022, 1x 2017\n",
      "Categories: 2x Knowledge Graph Question Answering Dataset, 3x Question Classifier\n",
      "Sources:  ['The SciQA Scientific Question Answering Benchmark for Scholarly Knowledge', 'A Rule-based Question Answering System for Reading Comprehension Tests', 'A Comparative Study of Question Answering over Knowledge Bases', 'Ripple Down Rules for question answering', 'The Structure and Performance of an Open-Domain Question Answering System']\n",
      "______________________\n",
      "Parent-Cluster ID: 1005\n",
      "Parent-Cluster Name: Specialized Knowledge Base Types\n",
      "Parent-Cluster Info: Contains classifications specific to querying specialized knowledge bases. Therefore to apply these classifications, it is required to run the question on that specific knowledge base.\n",
      "Amount of subclusters: 2\n",
      "Amount of types in all subclusters: 5\n",
      "Amount of different domains: 2\n",
      "Amount of different years: 3\n",
      "Amount of different categories: 1\n",
      "Amount of different sources: 3\n",
      "Names of Subclusters: ['ORKG and SPARQL Queries', 'Wikidata Qualifiers']\n",
      "Domains: 1x Scholarly, 2x General\n",
      "Years: 1x 2023, 1x 2021, 1x 2019\n",
      "Categories: 3x Knowledge Graph Question Answering Dataset\n",
      "Sources:  ['The SciQA Scientific Question Answering Benchmark for Scholarly Knowledge', 'What is in the KGQA Benchmark Datasets? Survey on Challenges in Datasets for Question Answering on Knowledge Graphs', 'LC-QuAD 2.0: A Large Dataset for Complex Question Answering over Wikidata and Dbpedia']\n",
      "______________________\n",
      "Parent-Cluster ID: 1006\n",
      "Parent-Cluster Name: Research-Orientation | Research-Focus | Scholarly Question Type\n",
      "Parent-Cluster Info: Focuses on scholarly and research-oriented questions\n",
      "Amount of subclusters: 8\n",
      "Amount of types in all subclusters: 8\n",
      "Amount of different domains: 2\n",
      "Amount of different years: 2\n",
      "Amount of different categories: 2\n",
      "Amount of different sources: 2\n",
      "Names of Subclusters: ['Research Output', 'Development Methods', 'Analytical Methods', 'Instance-Specific', 'Generalization ', 'Qualitative Modeling', 'Empirical Modeling', 'Analytic Modeling']\n",
      "Domains: 1x Scholarly, 1x Software Engineering\n",
      "Years: 1x 2024, 1x 2003\n",
      "Categories: 1x Knowledge Graph Question Answering Dataset, 1x Research Questions\n",
      "Sources:  ['Hybrid-SQuAD: Hybrid Scholarly Question Answering Dataset', 'Writing good software engineering research papers']\n",
      "______________________\n",
      "Parent-Cluster ID: 1007\n",
      "Parent-Cluster Name: Answer Credibility | Answer Reliability\n",
      "Parent-Cluster Info: Classifies questions by the credibility of the answer with regard to the truthfulness.\n",
      "Amount of subclusters: 5\n",
      "Amount of types in all subclusters: 9\n",
      "Amount of different domains: 4\n",
      "Amount of different years: 5\n",
      "Amount of different categories: 3\n",
      "Amount of different sources: 5\n",
      "Names of Subclusters: ['Factual', 'Opinion', 'Debate', 'Conversational', 'Predictive']\n",
      "Domains: 1x Requirements Engineering, 2x General, 1x Social Science, 1x Healthcare\n",
      "Years: 1x 2023, 1x 2022, 1x 2015, 1x 1984, 1x 2020\n",
      "Categories: 1x Knowledge Graph Question Answering Dataset, 2x Question Classifier, 2x Research Questions\n",
      "Sources:  ['Divide and Conquer the EmpiRE: A Community-Maintainable Knowledge Graph of Empirical Research in Requirements Engineering', 'A Non-Factoid Question-Answering Taxonomy', 'A Taxonomy for Classifying Questions Asked in Social Question and Answering', 'The Classification of Research Questions', 'Types of research questions: descriptive, predictive, or causal']\n",
      "______________________\n",
      "Parent-Cluster ID: 1008\n",
      "Parent-Cluster Name: Question Goal | Question Intent | Question Objective\n",
      "Parent-Cluster Info: Defines the overall goal or intent behind a question.\n",
      "Amount of subclusters: 7\n",
      "Amount of types in all subclusters: 14\n",
      "Amount of different domains: 3\n",
      "Amount of different years: 6\n",
      "Amount of different categories: 2\n",
      "Amount of different sources: 7\n",
      "Names of Subclusters: ['Exploratory', 'Reasoning', 'Problem Solving', 'Gap Spotting', 'Problematization', 'Focus', 'Design']\n",
      "Domains: 2x Software Engineering, 1x Design Science, 4x General\n",
      "Years: 1x 2008, 2x 2019, 1x 2003, 1x 2022, 1x 2000, 1x 2016\n",
      "Categories: 4x Research Questions, 3x Question Classifier\n",
      "Sources:  ['Selecting Empirical Methods for Software Engineering Research', 'Construction of Design Science Research Questions', 'Formulation of Research Question - Stepwise Approach', 'Writing good software engineering research papers', 'A Non-Factoid Question-Answering Taxonomy', 'The Structure and Performance of an Open-Domain Question Answering System', 'The question answering systems: A survey']\n",
      "______________________\n",
      "Parent-Cluster ID: 1009\n",
      "Parent-Cluster Name: Application-Specific\n",
      "Parent-Cluster Info: Groups those clusters where the type is specific to an application or use case and not useful for our task.\n",
      "Amount of subclusters: 12\n",
      "Amount of types in all subclusters: 12\n",
      "Amount of different domains: 4\n",
      "Amount of different years: 5\n",
      "Amount of different categories: 3\n",
      "Amount of different sources: 5\n",
      "Names of Subclusters: ['Problem Statement Identification', 'Research Question Utilization', 'Research Question Typology', 'Inquiry Mode Classification', 'Outcome Artifact Classification', 'Missing Term Resolution', 'Three Term Resolution', 'Human Relationship Inquiry', 'Multi Category Classification', 'NNP Answer Type', 'Resource Typed', 'Resource Untyped']\n",
      "Domains: 1x Design Science, 1x Vietnamese Language, 1x Spoken Natural Language Processing, 2x General\n",
      "Years: 1x 2019, 1x 2017, 1x 2015, 1x 2000, 1x 2021\n",
      "Categories: 1x Research Questions, 3x Question Classifier, 1x Knowledge Graph Question Answering Dataset\n",
      "Sources:  ['Construction of Design Science Research Questions', 'Ripple Down Rules for question answering', 'Linguistically Motivated Question Classification', 'The Structure and Performance of an Open-Domain Question Answering System', 'What is in the KGQA Benchmark Datasets? Survey on Challenges in Datasets for Question Answering on Knowledge Graphs']\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def print_with_occurence(prefix, data):\n",
    "    \"\"\"Helper Function to print the occurrence of items in a list.\"\"\"\n",
    "    count_dict = defaultdict(int)\n",
    "    for item in data:\n",
    "        count_dict[item] += 1\n",
    "    output_text = \"\"\n",
    "    for key, value in count_dict.items():\n",
    "        output_text += f\"{value}x {key}, \"\n",
    "    output_text = output_text[:-2]\n",
    "    print(f\"{prefix}: {output_text}\")\n",
    "    \n",
    "# -----------\n",
    "# Prepare the data for each iteration\n",
    "first_iteration = None\n",
    "second_iteration = None\n",
    "for iteration in cluster_increments:\n",
    "    iteration_count = iteration.get(\"iteration\", -1)\n",
    "    if iteration_count == 1:\n",
    "        first_iteration = iteration\n",
    "    if iteration_count == 2:\n",
    "        second_iteration = iteration\n",
    "\n",
    "for first_iteration_cluster in first_iteration.get(\"clusters\", []):\n",
    "    first_iteration_types = first_iteration_cluster.get(\"types\", [])\n",
    "        \n",
    "    has_match = False\n",
    "\n",
    "    for second_iteration_cluster in second_iteration.get(\"clusters\", []):\n",
    "        for second_iteration_subcluster in second_iteration_cluster.get(\"subclusters\", []):\n",
    "            second_iteration_types = second_iteration_subcluster.get(\"types\", [])\n",
    "\n",
    "            if len(first_iteration_types) != len(second_iteration_types):\n",
    "                continue\n",
    "\n",
    "            # Check if all types match\n",
    "            all_match = True\n",
    "            for first_iteration_type in first_iteration_types:\n",
    "                first_iteration_name = first_iteration_type.get(\"name\", \"unknown\")\n",
    "                has_type_match = False\n",
    "                for second_iteration_type in second_iteration_types:\n",
    "                    second_iteration_name = second_iteration_type.get(\"name\", \"unknown\")\n",
    "                    if first_iteration_name == second_iteration_name:\n",
    "                        has_type_match = True\n",
    "                        break\n",
    "                if not has_type_match:\n",
    "                    all_match = False\n",
    "                    break\n",
    "            if all_match:\n",
    "                has_match = True\n",
    "                break\n",
    "        if has_match:\n",
    "            break\n",
    "    if not has_match:\n",
    "        print(f\"First Iteration Types: {[type.get('name', 'unknown') for type in first_iteration_types]}\")\n",
    "        print(\"______________________\")\n",
    "# ----------\n",
    "# ----------\n",
    "# Create a mapping of metadata for each paper\n",
    "metadata_mapping = {}\n",
    "for paper in extraction_mapping:\n",
    "    title = paper.get(\"title\", \"No title\")\n",
    "    year = paper.get(\"year\", \"No year\")\n",
    "    authors = paper.get(\"authors\", \"No authors\")\n",
    "    doi = paper.get(\"doi\", \"No doi\")\n",
    "    category = paper.get(\"category\", \"No category\")\n",
    "    domain = paper.get(\"domain\", \"No domain\")\n",
    "    metadata_mapping[title] = {\n",
    "        \"year\": year,\n",
    "        \"authors\": authors,\n",
    "        \"doi\": doi,\n",
    "        \"category\": category,\n",
    "        \"domain\": domain,\n",
    "    }\n",
    "# ----------\n",
    "# ----------\n",
    "# Print the metadata for each cluster\n",
    "for iteration in cluster_increments:\n",
    "    if not iteration.get(\"iteration\", -1) == 2:\n",
    "        continue\n",
    "\n",
    "    for cluster in iteration.get(\"clusters\", []):\n",
    "        cluster_id = cluster.get(\"id\", \"unknown\")\n",
    "        cluster_name = cluster.get(\"name\", \"unknown\")\n",
    "        cluster_info = cluster.get(\"info\", \"No info\")\n",
    "        print(\"______________________\")\n",
    "        print(f\"Parent-Cluster ID: {cluster_id}\")\n",
    "        print(f\"Parent-Cluster Name: {cluster_name}\")\n",
    "        print(f\"Parent-Cluster Info: {cluster_info}\")\n",
    "        subclusters = cluster.get(\"subclusters\", [])\n",
    "        types = []\n",
    "        subcluster_names = []\n",
    "        sources = {}\n",
    "        domains = set()\n",
    "        years = set()\n",
    "        categories = set()\n",
    "        for subcluster in subclusters:\n",
    "            subcluster_types = subcluster.get(\"types\", [])\n",
    "            subcluster_id = subcluster.get(\"id\", \"unknown\")\n",
    "            subcluster_info = subcluster.get(\"info\", \"No info\")\n",
    "            subcluster_name = subcluster.get(\"name\", \"unknown\")\n",
    "            subcluster_names.append(subcluster_name)\n",
    "            for type_dict in subcluster_types:\n",
    "                name = type_dict.get(\"name\", \"unknown\")\n",
    "                source = type_dict.get(\"source\", \"unknown\")\n",
    "                domain = metadata_mapping.get(source, {}).get(\"domain\", \"unknown\")\n",
    "                year = metadata_mapping.get(source, {}).get(\"year\", -1)\n",
    "                category = metadata_mapping.get(source, {}).get(\"category\", \"unknown\")\n",
    "                types.append(name)\n",
    "                sources[source] = {\n",
    "                    \"domain\": domain,\n",
    "                    \"year\": year,\n",
    "                    \"category\": category\n",
    "                }\n",
    "                domains.add(domain)\n",
    "                years.add(year)\n",
    "                categories.add(category)\n",
    "        print(f\"Amount of subclusters: {len(subclusters)}\")\n",
    "        print(f\"Amount of types in all subclusters: {len(types)}\")\n",
    "        print(f\"Amount of different domains: {len(domains)}\")\n",
    "        print(f\"Amount of different years: {len(years)}\")\n",
    "        print(f\"Amount of different categories: {len(categories)}\")\n",
    "        print(f\"Amount of different sources: {len(sources)}\")\n",
    "        print(f\"Names of Subclusters: {subcluster_names}\")\n",
    "\n",
    "        src_domains = [source[\"domain\"] for source in sources.values()]\n",
    "        src_years = [source[\"year\"] for source in sources.values()]\n",
    "        src_categories = [source[\"category\"] for source in sources.values()]\n",
    "        src_names = list(sources.keys())\n",
    "        print_with_occurence(\"Domains\", src_domains)\n",
    "        print_with_occurence(\"Years\", src_years)\n",
    "        print_with_occurence(\"Categories\", src_categories)\n",
    "        print(\"Sources: \", src_names)\n",
    "# -----------\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
