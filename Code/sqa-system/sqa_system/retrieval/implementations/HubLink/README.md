# HubLink Retriever

> This retriever has been used in our experiments

## Overview

The HubLink Retriever is a novel retriever that we have developed ourselves as part of the Master Thesis. It is our main contribution and the main focus of the experiments.

## Folder Structure

```
├── models/     # The data models of the retriever  
│   ├── entity_with_direction.py    # The entity with direction model
│   ├── hub_link_settings.py    # All parameters of the retriever
│   ├── hub_path.py   # The hub path model
│   ├── hub.py   # The hub model
│   ├── processed_question.py   # The processed question model
│   └── source_document_summary.py   # The source document summary model
├── retrieval/  
│   ├── base_retrieval_strategy.py  # The base class for all retrieval strategies
│   ├── direct_retrieval_strategy.py    # The direct retrieval strategy
│   └── traversal_retrieval_strategy.py   # The graph traversal retrieval strategy
├── utils/   
│   ├── answer_generator.py     # Class for partial and final answer generation
│   ├── hub_builder.py  # Class for building the hub structures
│   ├── hub_finder.py   # Class for finding the hub structures in the graph
│   ├── hub_indexer.py  # Class for indexing the hub structures
│   ├── hub_source_handler.py   # Class for handling the linking procedure
│   └── vector_store.py # Class for the vector store and required functions
└── hub_link_retriever.py   # The main entry point of the retriever
```

## Approach Explanation

> **Note**: A detailed explanation of the approach can be found in the Master Thesis. In the following we give a quick overview of the approach.

### Indexing Phase

The process begins with a set of start entities in the graph that serve as initial points for indexing. Starting from these entities, each path in the Knowledge Graph (KG) is traversed while searching for HubRoot entities. These identified entities are stored in a list and processed sequentially.

For each identified HubRoot entity, the first step is to extract the HubPaths from the graph. These paths start from the root entity of the hub and lead to the end entities of the hub, which are either leaf nodes in the graph or other hub entities.

Each HubPath undergoes further processing. First, the entire path is passed to a language model (LLM), which creates a textual description of the path. Additionally, all triples within the path and all entities from these triples are extracted. These three pieces of information, the textual description, the triples, and the entities, are then mapped into a low-dimensional vector space using an embedding model. After this transformation, these vectors are stored in a vector store. To each vector, additional metadata are attached that are later required for the retrieval phase of the algorithm. This metadata includes the root identifier of the hub to identify to which hub the vector belongs. In addition, the metadata contain the path description that was previously generated by the LLM. This is true even for the vectors of the entities and triples that are part of the path. 

After these initial hubs have been indexed, the process repeats for the next traversal level of the graph. The new starting entities for this traversal level are collected during the processing of the previous level. The indexing process continues until either the maximum number of traversal levels is reached or no new hubs are found.

### Direct Retrieval Strategy

This strategy requires only the input question and the vector store that contains the previously indexed hub structures. During query time, this strategy does not require additional access to the graph.

First, the natural language question is transformed into a vector using the same embedding model as in the indexing phase. This vector is then used to perform a search in the vector store. The search is configured to collect a predetermined number of $k$ hubs, each with a fixed number of $n$ HubPaths sorted by their similarity to the question.

Once $k$ hubs have been found, each with $n$ HubPaths, the Linking process of the HubLink Retriever begins. During this process, additional information is searched for in an external database using the identifier of the hub, which further enriches the context of the hub beyond the knowledge collected from the graph. This could be, for example, text passages from original publications.

After this Linking process, all the necessary information about the hub has been collected. Next, for each individual hub, a partial answer is generated based on the aggregated information from that single hub and the original question. This is done by passing the information from the hub along with the original question in a prompt to an LLM. The LLM first checks if it is possible to provide a partial answer to the question based on this information. If a partial answer can be generated, it is generated by the LLM in a second step.

Subsequently, all generated partial answers are consolidated to create a final answer. First, the system checks if any partial answers were created. If not, no final answer can be generated. However, if partial answers exist, these are passed to the LLM along with the original question. The LLM then generates the final answer based on this information.

### Graph Traversal Retrieval Strategy

In addition to the question, this strategy requires defining a starting point in the graph which is referred to as the Topic Entity.

Initially, a search process begins on the graph. Starting from the topic entity, all paths are traversed to identify HubRoot entities. During this process, the entities on each path are sequentially checked until the first HubRoot entity is found. These HubRoot entities are then stored in a list. At the end of this search, the list contains the first found HubRoot entity for each path originating from the starting point.

After collecting these HubRoot entities, the corresponding HubPaths are loaded from the vector store using the identifier of the hub. For each hub, the top $n$ paths are retrieved, sorted by their similarity to the question. The total score for the hub is then calculated from the average similarity values of HubPaths. In a subsequent pruning step, the $k$ best hubs are selected based on this score.

Next, the Linking process and subsequent answer generation are performed exactly as in the Direct Retrieval Strategy. However, if no partial answers are found, the strategy can now be repeated starting from the graph search process. For this purpose, the search continues from where a path ended at a HubRoot entity in the previous step.