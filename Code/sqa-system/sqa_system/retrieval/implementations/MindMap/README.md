# MindMap Retriever

> This retriever has been used in our experiments

## Overview
The MindMap approach embeds the entities of the graph in a pre-processing step. At query time, the approach tasks the LLM to extract entities from the question and then performs a nearest neighbor search to retrieve the most similar entities from the graph based on the embedding of the question. For each identified entity in the graph, the approach builds evidence subgraphs. The information from the subgraphs are consolidated which are then prompted to the LLM to generate the final answer. 

The approach is authored by Wang et al. in the paper ["MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large Language Models"](https://arxiv.org/pdf/2308.09729).

We implemented the retriever by adapting the offical code from the [MindMap repository](https://github.com/wyl-willing/MindMap/tree/main) with the commit number 0411a54. 

## Approach Explanation

The MindMap retriever is a knowledge graph-based retrieval approach that utilizes a large language model (LLM) to extract entities from the question and build evidence subgraphs. The retriever starts by embedding the entities of the knowledge graph in a pre-processing step. At query time, the retriever tasks the LLM to extract entities from the question and then performs a nearest neighbor search to retrieve the most similar entities from the graph based on the extracted entities from the question. For each identified entity in the graph, the retriever builds evidence subgraphs. Two types of subgraph are build. First, the shortest paths between the identified entities are constructed forming the first subgraph. Second, the 1-Hop neighbors of the identified entities are retrieved forming the second subgraph. The information from the subgraphs are converted into natural language descriptions using the LLM. The final answer is generated by prompting the LLM with the natural language descriptions of the subgraphs and the original question. 

## Detailed Steps with Changes
1. First the Retriever needs to index the Knowledge Graph. For this all entities in the graph are extracted and subsequently embedded.
    1. In the original code, the embeddings are loaded from a prepared file. In our implementation we adapted the code to work with a vector store instead of using a text file where the distance between each embedding is subsequently calculated. This ensures that the retrieval is faster and more efficient making it competitive with other retrieval approaches
2. Then, a Question is asked and no Topic Entity is needed. An extraction of entities from the question is done using an LLM
    1. In the original Code, the extraction is already pre-prepared for each question. Because in our implementation we cant be sure what questions to expect, we adapted the code to extract the entities from the question using an LLM.
3. The extracted entities are embedded and for each extracted entity, the most similar entity from the Graph is fetched and stored in a list `match_kg`.
    1. In the original, the entity embeddings are stored in a text file and iteratively the distance is calculated using cosine similarity. We are using a vector store for this.
5. For each fetched entity in `match_kg`, the shortest paths from the first entity in `match_kg` to each other entity in `match_kg` are searched for. After the paths are returned, the start entity is changed to the candidate that was found inside of the path or to the end entity of the last search. This creates a chain of paths between the entities. It either takes a shortest path that includes any other entity from the candidate list or it takes a set amount of the shortest paths that lead from one entity to the end entity
    1. The implementation provided by the authors did not include a solution for finding the shortest paths between the entities, which is why we implemented a bidirectional BFS search ourselves
6. Then the code iterates over each shortest path and collects the first element from each path to then equally distribute the starting entities across the final result paths. Meaning that the amount of result paths is reduced to a set constant amount and across these the starting entities are equally distributed
7. Then for each path the information is aggregated into a single prompt for which the LLM is tasked to transform the path information into a natural language description
    1. Because the prompt had grammatical errors in the original code, we adapted the prompt to be grammatically correct. We also added a few-shot example to the prompt.
8. Then for each extracted entities from the graph the algorithm also gets the next 1-Hop Neighbors around the entity in the graph.
9. It then aggregates all the entities and their neighbors and proceeds to prompt an LLM to transform the Entity and Neighbor Subgraph Information into a natural language representation
    1. Because the prompt had grammatical errors in the original code, we adapted the prompt to be grammatically correct. We also added a few-shot example to the prompt.
10. It then proceeds to task the LLM to generate a final answer based on the natural language description of the paths, the entities with their neighbors and the original question
    1. Because the prompt had grammatical errors in the original code, we adapted the prompt to be grammatically correct. We also added a few-shot example to the prompt.


## Implementation
The implementation of the 