{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "current_file = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_file)\n",
    "\n",
    "dataset_deep = os.path.join(current_file, \"deep_distributed_graph_dataset.csv\")\n",
    "dataset_reduced = os.path.join(parent_dir, \"reduced\", \"reduced_deep_distributed_graph_dataset.csv\")\n",
    "deep_graph_df = pd.read_csv(dataset_deep)\n",
    "reduced_graph_df = pd.read_csv(dataset_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markdown table saved to output_table.md\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "COLUMNS_TO_INCLUDE = [\n",
    "    \"use_case\",\n",
    "    \"retrieval_operation\",\n",
    "    \"based_on_template\",\n",
    "    \"updated template\",\n",
    "    \"semi-typed\"\n",
    "]\n",
    "\n",
    "missing_columns = [col for col in COLUMNS_TO_INCLUDE if col not in deep_graph_df.columns]\n",
    "df_selected = deep_graph_df[COLUMNS_TO_INCLUDE]\n",
    "\n",
    "# Convert the selected DataFrame to a Markdown table\n",
    "# Using 'pipe' format for typical Markdown tables\n",
    "markdown_table = tabulate(df_selected, headers='keys', tablefmt='pipe', showindex=False)\n",
    "with open(\"output_table.md\", \"w\") as f:\n",
    "    f.write(markdown_table)\n",
    "    print(f\"Markdown table saved to output_table.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filter out all those rows where the topic_entity_id is not \"R659055\"\n",
    "filtered_deep_graph_df = deep_graph_df[deep_graph_df['topic_entity_id'] != 'R659055']\n",
    "\n",
    "# Save the filtered DataFrame to a new CSV file\n",
    "filtered_deep_graph_df.to_csv(os.path.join(parent_dir, \"reduced\", \"topic_entity_test_dataset.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified deep graph dataset saved to /home/marco/master_thesis_implementation/sqa-system/experiments/qa_datasets/qa_datasets/full/modified_deep_graph_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# for each row in reduced_graph_df find the corresponding row by the \"uid\" in deep_graph_df\n",
    "# replace each column in deep_graph_df with the corresponding column in reduced_graph_df overwriting the values. For any column that is not in reduced_graph_df, keep the value from deep_graph_df\n",
    "for index, row in reduced_graph_df.iterrows():\n",
    "    uid = row[\"uid\"]\n",
    "    deep_graph_row = deep_graph_df[deep_graph_df[\"uid\"] == uid]\n",
    "    if not deep_graph_row.empty:\n",
    "        for column in deep_graph_row.columns:\n",
    "            if column in row:\n",
    "                deep_graph_df.loc[deep_graph_df[\"uid\"] == uid, column] = row[column]\n",
    "\n",
    "# For every uid that appears in the reduced dataset, i want to mark the row in the deep_graph_df as \"used_in_reduced\" \n",
    "deep_graph_df[\"used_in_reduced\"] = False\n",
    "for index, row in reduced_graph_df.iterrows():\n",
    "    uid = row[\"uid\"]\n",
    "    deep_graph_df.loc[deep_graph_df[\"uid\"] == uid, \"used_in_reduced\"] = True\n",
    "                \n",
    "\n",
    "# save the modified deep_graph_df to a new csv file\n",
    "output_file = os.path.join(current_file, \"modified_deep_graph_dataset.csv\")\n",
    "deep_graph_df.to_csv(output_file, index=False)\n",
    "print(f\"Modified deep graph dataset saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the dataset:\n",
      "uid\n",
      "semi-typed\n",
      "question\n",
      "golden_answer\n",
      "source_ids\n",
      "golden_doc_chunks\n",
      "golden_triples\n",
      "is_generated_with\n",
      "topic_entity_id\n",
      "topic_entity_value\n",
      "hops\n",
      "based_on_template\n",
      "updated template\n",
      "use_case\n",
      "retrieval_operation\n",
      "graph_representation\n",
      "answer_format\n",
      "answer_type\n",
      "condition_type\n"
     ]
    }
   ],
   "source": [
    "columns = df.columns\n",
    "print(\"Columns in the dataset:\")\n",
    "for column in columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def parse_list_string(list_string):\n",
    "    if pd.isna(list_string):\n",
    "        return []\n",
    "    if not isinstance(list_string, str):\n",
    "        return []\n",
    "    if isinstance(list_string, list):\n",
    "        return list_string\n",
    "    try:\n",
    "        return ast.literal_eval(list_string)\n",
    "    except (ValueError, SyntaxError):\n",
    "        print(f\"Error parsing list string: {list_string}\")\n",
    "        return []\n",
    "\n",
    "df['golden_triples'] = df['golden_triples'].apply(parse_list_string)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
