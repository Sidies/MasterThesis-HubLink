
% Surveys 
% \cite{pan_unifying_2024,peng_graph_2024,jin_large_2024,feng_trends_2023,li_survey_2024,agrawal_can_2024,procko_graph_2024}

% Baseline Retriever Occurence
% - Mindmap(\cite{wen_mindmap_2024}): \cite{pan_unifying_2024}, \cite{peng_graph_2024}, \cite{agrawal_can_2024}
% - StructGPT(\cite{jiang_structgpt_2023}): \cite{pan_unifying_2024}, \cite{peng_graph_2024}, \cite{jin_large_2024}, \cite{agrawal_can_2024}
% - ToG(\cite{sun_think--graph_2024}): \cite{pan_unifying_2024}, \cite{peng_graph_2024}, \cite{jin_large_2024}
% - FiDeLiS(\cite{sui_fidelis_2024}):
% - DiFar(\cite{baek_direct_2023}: \cite{peng_graph_2024}

% Our approach is for \gls{qa} over \gls{kg} or short \gls{kgqa}, which means a question is 

% The integration of \glspl{llm} has significantly accelerated research into \gls{kgqa}, leading to diverse retrieval approaches, as documented in recent surveys \cite{pan_unifying_2024,peng_graph_2024,jin_large_2024,feng_trends_2023,li_survey_2024,agrawal_can_2024,procko_graph_2024}. Nevertheless, there exists a research gap for schema-agnostic and training-free methods for the scholarly domain. To contextualize the contributions of this paper, this section reviews related work. 

\section{Using Large Language Models for KGQA}
% Am Anfang nochmal Surveys hervorheben und HubLink einordnen?
% (AK) -> Gab es nicht hier sogar eine Tabelle mit "Big Picture"? 

In the following, we examine existing \gls{kgqa} retrieval strategies that use an \gls{llm} and are relevant to our proposed HubLink approach (\hyperref[enum:c1]{\textbf{C1}}) across four categories. First, we introduce methods that specifically target the scholarly domain. Next, we focus on \gls{kgqa} approaches that utilize an \gls{llm} to conduct stepwise reasoning on the graph. Then, we review techniques centered on dynamic subgraph construction to conduct inference for \gls{kgqa}. Last, we conclude with methods based on converting graph knowledge into a vector space to perform inference using distance measures.

\subsection{Approaches for QA on Scholarly Knowledge Graphs}
\label{sec:related_work_kgqa_on_scholarly}

Recent efforts in scholarly \gls{qa} have explored the integration of \glspl{llm} with \glspl{rkg}, primarily through \emph{semantic parsing} methods. These approaches translate natural language questions into formal queries, such as SPARQL, by identifying relevant entities and relations in the underlying \gls{kg} \cite{zhang_survey_2023}.

JarvisQA \cite{jaradeh_question_2020} leverages tabular data converted into triples and uses a language model to textualize these triples. The final answer is then retrieved using a BERT-based model \cite{devlin_bert_2019}. However, this system operates on structured tabular data provided by the \gls{orkg} rather than performing direct reasoning over an \gls{rkg}. Similarly, DBLP-QuAD \cite{banerjee_dblp-quad_2023} fine-tunes a T5 model \cite{raffel_exploring_2023} to translate natural language questions into SPARQL queries. However, this method depends on large annotated datasets and effective entity linking, which are often unavailable for newly constructed scholarly \glspl{kg}. Another approach, KGMistral \cite{li_kgmistral_2024}, utilizes a \gls{rag} framework where pre-prepared SPARQL query templates are filled to directly retrieve relevant triples from the \gls{kg}. These triples are then converted into natural language and provided as context for the \gls{llm}. Similarly, \textcite{taffa_leveraging_2023} propose a retrieval-based strategy that reuses the pre-prepared SPARQL query associated with the most similar question in the training set. Although efficient in controlled settings, this reuse of existing templates struggles to generalize beyond the training distribution.


The SciQA dataset has been central to the evaluation of most of these methods, where they have shown strong results. However, these results can be misleading because the questions in the dataset have been automatically generated from seed questions, which an \gls{llm} might be able to identify inherent patterns from \cite{lehmann_large_2024}. Moreover, many of the test questions in the dataset share schema elements with training data, reducing the challenge of generalization \cite{jiang_structure_2023}. Finally, this benchmark does not take into account that semantic parsing methods tend to degrade when applied to larger, dynamic \glspl{kg}, where unseen schema components and entities are common \cite{gu_knowledge_2022}. Furthermore, their reliance on task-specific training examples limits adaptability and scalability.

In response, prompt-based and schema-agnostic semantic parsing methods have been introduced. \textcite{lehmann_large_2024} compare fine-tuned and prompting-based approaches on SciQA, finding that zero-shot prompting has a poor performance but that few-shot prompting can rival fine-tuning in accuracy while offering better adaptability. Still, using few-shot prompting requires examples that do not translate well to unseen data. Next, \textcite{jiang_structure_2023} propose a two-stage prompting framework that incorporates ontology information into both structural and content-level prompts. Although this strategy achieves strong performance, its effectiveness diminishes with larger ontologies, posing scalability challenges.

In contrast to these approaches, the proposed HubLink retrieval approach is not semantic parsing based and does not require annotated training data or prior schema knowledge. Instead, it embeds subgraphs rooted in specific nodes and generates text representations of paths using a general-purpose embedding model. This allows the method to dynamically adapt to evolving schema, making it more robust and scalable for real-world applications.

\subsection{LLM-Guided Stepwise KGQA Approaches}
\label{sec:related_work_stepwise_kgqa}

Many current training-free \gls{kgqa} approaches proposed in the literature are stepwise reasoning approaches. These methods typically decompose the complex reasoning task into smaller, manageable steps, iteratively querying the \gls{kg} and using the \gls{llm} to guide the process towards an answer. Similarly to our HubLink approach, many of these methods utilize a pre-trained \gls{llm} without requiring task-specific fine-tuning. However, they fundamentally differ in how they interact with and structure the \gls{kg} information during reasoning.

A prominent strategy involves employing the \gls{llm} as an active agent or controller within the reasoning process. For instance, \gls{tog} \cite{sun_think--graph_2024} actively involves the \gls{llm} in multi-hop reasoning by using a beam search strategy where the \gls{llm} evaluates and prunes potential reasoning paths. Knowledge Solver (KSL) \cite{feng_knowledge_2023} frames \gls{kg} traversal as a decision-making process within a dialogue-like prompt structure, where the \gls{llm} selects subsequent entities based on relation prompts. \textcite{sun_oda_2024} propose an Observation-Driven Agent (ODA), which operates in a cycle of observation, action, and reflection. In this cycle, a subgraph is expanded based on similarity, an \gls{llm} selects between further exploration, path discovery, or answering, and the internal memory is updated to guide future steps. GRAPH-COT \cite{jin_graph_2024} uses the \gls{llm} to hypothesize required information, issue-specific graph function calls such as node retrieval or neighbor inspection, and integrate the results in a final answer. StructGPT \cite{jiang_structgpt_2023} provides a general framework using an Iterative Reading-then-Reasoning process, linearizing information extracted from structured sources like \glspl{kg} or tables via specialized interfaces that the \gls{llm} uses. FiDeLiS \cite{sui_fidelis_2024} combines a Path-RAG component for retrieving relevant entities and relations with a deductive verification beam search module where the \gls{llm} iteratively assembles and validates multi-hop paths.

There are also approaches that extend the retrieval to further enhance the context available to the \gls{llm}. For example, hybrid strategies such as ToG-2 \cite{ma_think--graph_2024} integrate both structured \gls{kg} exploration and unstructured text retrieval during the inference to iteratively refine the search using \gls{llm} guidance. Other approaches address \gls{kg} incompleteness. For example Generate-on-Graph (GoG) \cite{xu_generate--graph_2024} allows the \gls{llm} to supplement missing facts by generating plausible triples based on its internal knowledge alongside retrieved \gls{kg} information.

Although the traversal strategy of HubLink incorporates an iterative process for subsequent retrievals if initial information is insufficient, its core mechanism diverges significantly from the stepwise reasoning methods mentioned above. The approaches discussed above primarily focus on dynamic, on-the-fly traversal and reasoning, where the \gls{llm} often guides the exploration entity by entity. In contrast, HubLink involves retrieving precomputed and embedded subgraph structures referred to as \emph{hubs} rooted at specific node types. The reasoning and inference process operates predominantly on these retrieved structured hub representations rather than solely on the sequence of entities traversed during a dynamic search. This pre-structuring and retrieval of meaningful subgraphs is the central difference to other stepwise approaches. We argue that by using this strategy, the transitive relations of entities not yet reached can be incorporated into the reasoning, a problem that current stepwise reasoning approaches struggle with, as outlined in Section~\ref{sec:discussion_on_evaluation_results} of the thesis.

\subsection{KGQA using Contextual Subgraph Construction}
\label{sec:related_work_kgqa_subgraph_construction}

Another related line of research focuses on constructing subgraphs dynamically during the retrieval process to provide contextual information for \gls{kgqa}, leveraging \glspl{llm} without additional training or fine-tuning. These methods typically identify relevant entities in the question and explore the \gls{kg} to build a localized graph structure relevant to the query.

For example, Mindmap \cite{wen_mindmap_2024} uses prompts to guide an \gls{llm} in constructing path-based and neighbor-based evidence subgraphs, which are then aggregated into a reasoning graph used for answer generation in order to preserve the structure of the graph during inference. \gls{kg}-GPT \cite{kim_kg-gpt_2023} first decomposes the question into potential triples, retrieves candidate relations for identified entities, and builds an evidence subgraph from these components before having the \gls{llm} reason over the linearized result. Reasoning on Efficient Knowledge Paths (RoK) \cite{wang_reasoning_2024} uses a chain-of-thought approach to extract key entities, generates multi-hop reasoning paths between them, ranks these paths using PageRank, and forwards the resulting subgraph to the \gls{llm}.

Although these approaches utilize subgraphs as contexts for the \gls{llm}, they differ fundamentally from HubLink. The core distinction lies in both when and how the subgraphs are created. The methods described above construct subgraphs dynamically at query time, often starting from entities mentioned in the question and expanding based on neighborhood proximity, path generation, or prompt-guided assembly. In contrast, HubLink employs an offline indexing process where subgraphs or so-called \emph{hubs} are precomputed based on predefined node types acting as semantic anchors. These hubs are designed to represent coherent semantic units, capturing meaningful relationships extending from the root node. HubLink retrieves these entire pre-constructed hubs rather than constructing subgraphs dynamically. This precomputation allows for faster retrieval and ensures that the retrieved context aligns with predefined semantic structures. Dynamic methods, on the other hand, build context based on immediate query features and graph topology without necessarily enforcing a specific semantic coherence or tracking information origin in the same way the hub definition of HubLink allows.


\subsection{Utilizing Vector Representations for KGQA}
\label{sec:related_work_utilizing_vectors}

Another direction of \gls{kgqa} is the use of dense vector representations to capture knowledge and facilitate retrieval. These approaches vary in what they embed and whether they require dedicated training.

One category involves directly embedding the \gls{kg}, using pre-trained models without \gls{kg}-specific training. Direct Fact Retrieval (DiFaR) \cite{baek_direct_2023} exemplifies this by encoding individual \gls{kg} triples into dense vectors during an offline phase. At query time, relevant triples are retrieved via nearest-neighbor search between the question embedding and the triple embeddings and then provided as context to an \gls{llm}. However, this approach primarily considers isolated triples, potentially missing the broader context captured in multi-hop paths or larger graph structures. HubLink does not embed isolated triples. Instead, it focuses on precomputed subgraph structures and embeds rich textual descriptions derived from the paths, triples, and entities within these hubs. This allows capturing more complex relational context than individual triples.

A different category involves training dedicated Knowledge Graph Embedding (\gls{kg}E) models \cite{cao_knowledge_2024, pan_unifying_2024}. These methods learn vector representations for entities and relations by training specific models on the structure of the \gls{kg}. For example, Pretrain-\gls{kg}E \cite{zhang_pretrain-kge_2020} integrates pre-trained language models like BERT and fine-tune them on \gls{kg} triples. KEPLER \cite{wang_kepler_2020} employs a dual-objective training combining \gls{kg}E and masked language modeling. \textcite{nayyeri_integrating_2023} use specialized algebraic embeddings like quaternion models in their training. These approaches aim to capture implicit semantic relationships within the \gls{kg} but necessitate a training phase, often requiring significant graph data and computational resources. Crucially, HubLink leverages general-purpose pre-trained embedding models to encode these textual descriptions, requiring no dedicated \gls{kg}E training or fine-tuning. This design choice makes HubLink easily applicable to different \glspl{kg} without the need for training data or processes while still aiming to provide a semantically rich structured context for downstream \gls{llm} reasoning.

% # Code Generation

% KnowledGPT by \textcite{wang_knowledgpt_2023}, is a \gls{kgqa} approach that uses a program of thought prompting strategy in which the \gls{llm} generates Python code to interact with the \gls{kg} through predefined functions.

% # Graph Formatting

% GraphText: Graph Reasoning in Text Space
% Their approach can technically be adapted for \gls{kgqa} but their implementation is for the classification and not the QA task
% \textcite{TODO} introduce GRAPHTEXT, a framework that converts the graph into a natural language sequence by constructing a graph-syntax tree that encodes both the attributes and the relationships of the node. By traversing this tree, the framework generates text prompts that can be directly processed by \gls{llm} to perform graph reasoning tasks.