
\section{Taxonomy Development and Question Classification}
% https://ise-fizkarlsruhe.github.io/nfdicore/docs/questions/#

As part of this thesis, we provide a taxonomy for the classification of characteristics of a \gls{kgqa} system on the literature search task (\hyperref[enum:c2]{\textbf{C2}}). To support the development of this taxonomy, we also provide a systematic construction approach (\hyperref[enum:c2]{\textbf{C2.1}}). In the following, we first review the evolution of systematic approaches for taxonomy construction and evaluation. This involves discussing established methods from \gls{is} and \gls{se}, their practical application challenges, and identified limitations with respect to operationalization and systematic adaption of existing classifications. Then, we present an overview of the landscape in question classification with a particular focus on the application within \gls{qa} systems and \gls{kgqa} benchmarks. We highlight existing practices but also identify critical gaps concerning the need for a comprehensive and generalized taxonomy.

\subsection{Systematic Approaches to Taxonomy Construction and Evaluation}
\label{sec:related_work_taxonomy_construction}

Taxonomies serve as fundamental artifacts across numerous disciplines, including \gls{is} and \gls{se}. They provide essential structure for complex bodies of knowledge to facilitate understanding and enable research. Historically, taxonomies in both \gls{is} and \gls{se} have not been developed following any systematic approach \cite{usman_taxonomies_2017,nickerson_method_2013}. In response to this deficit, \textcite{nickerson_method_2013} proposed a systematic method for taxonomy development, which is grounded in taxonomy literature from disciplines such as biology and social sciences. The approach outlines an organized sequence of steps, which involves identifying the meta-characteristic and ending condition criteria, followed by repeated cycles of empirical-to-conceptual or conceptual-to-empirical analysis depending on available data and the expertise of the researcher. This method is intended to steer researchers away from ad-hoc methods toward a more intentional and systematic approach. However, despite being widely referenced in the \gls{is} taxonomy literature since its publication, subsequent analysis by \textcite{kundisch_update_2022} revealed that the adoption of the \textcite{nickerson_method_2013} method in practice has been inconsistent and often lacked transparency, which suggests challenges in the practical operationalization of the method. Consequently, \textcite{kundisch_update_2022} adapt the original taxonomy construction approach to directly address the observed issue of inconsistent adoption, lack of transparency, and the infrequent evaluation of taxonomies.

Parallel efforts to provide systematic guidance can be observed in the \gls{se} domain. One of the first studies to describe a systematic approach to taxonomy development in \gls{se} is provided by \textcite{bayona-ore_critical_2014}. They present a method for creating taxonomies based on a systematic review and industry experience. Their approach consists of several phases, such as planning, identification and extraction, design and construction, testing and validation, and deployment. The approach was later revisited by \textcite{usman_taxonomies_2017}, who identified limitations, including the inclusion of activities outside the scope of taxonomy design, its basis in the limited literature, and a lack of explicit guidance for crucial methodological decisions. In response, they proposed a revised method that reduces the number of phases and focuses only on essential activities while also introducing new ones to support more thorough and flexible taxonomy development.

Although significant advances have been made in providing systematic construction methods, as illustrated by the above methods \cite{kundisch_update_2022,nickerson_method_2013,bayona-ore_critical_2014,usman_taxonomies_2017}, the operationalization of these processes still presents challenges. The noted inconsistencies and calls for more implementation guidance \cite{kundisch_update_2022} suggest that researchers may require more detailed, step-by-step, and potentially tool-supported guidance to effectively apply these systematic approaches. Furthermore, while methods for developing new taxonomies exist, the literature indicates that taxonomies are rarely revisited, revised, or extended \cite{usman_taxonomies_2017}. This infrequent revision suggests that researchers tend to build new taxonomies from scratch or without clear reference to existing classifications rather than systematically synthesizing, adapting, and refining knowledge present in the existing literature. Although \textcite{kundisch_update_2022} recommend accounting for and referring to existing taxonomies, current methods primarily focus on the construction of new taxonomies. They lack a specific and operational process for systematically synthesizing and adapting existing taxonomies. This identified gap is addressed by our Contribution \hyperref[enum:c2]{\textbf{C2.1}}. Our systematic taxonomy construction approach provides a systematic process for initializing taxonomies based on existing literature, incrementally refining them using quantitative metrics (from \textcite{kaplan_introducing_2022}), and offering tool support to aid researchers in execution.

% However, explicit guidance for the quantitative evaluation of taxonomies has not been provided by previous construction approaches. This observed deficit motivated \textcite{kaplan_introducing_2022} to introduce a dedicated method specifically to evaluate taxonomies in \gls{se}. Their method is a three-step process that focuses on evaluating the structure, applicability, and purpose of the taxonomy through specific metrics. 

% The authors \textcite{nickerson_method_2013} explicitly state difficulty in providing sufficient conditions for usefulness and detailed guidance for evaluation after the taxonomy is built, noting that the utility is ultimately demonstrated by use over time.

\subsection{Question Classification for Scholarly QA on Knowledge Graphs}
\label{sec:related_work_kgqa_classifiation}

\gls{qa} systems are typically assessed using benchmarks that include questions asked to such systems. To characterize these questions and understand which specific types of questions are used during evaluation, a taxonomy is helpful that provides guidelines for the classification of such questions. In the past, several works have utilized this approach to ensure diversity when developing datasets for \gls{kgqa}. \textsc{LC-QuAD 2.0} \cite{dubey_lc-quad_2019} incorporates 10 types of questions, such as single or multi fact, boolean, counting, or ranking. Furthermore, specifically targeting scholarly graphs, the dataset SciQA \cite{auer_sciqa_2023} includes various types of questions, including complex, factoid, and non-factoid questions, addressing aspects like superlatives, negation, counting, or ranking. \textsc{SciQA} also provides statistics on the distribution of questions across categories such as query shapes, query classes, query types, query components, and triple patterns. Another notable dataset in the scholarly domain that also uses a taxonomy for its dataset design is \textsc{DBLP-QuAD} \cite{banerjee_dblp-quad_2023}. The authors explicitly categorize the questions into 10 different types such as single or multi fact, boolean, union, or disambiguation. Moreover, \textcite{jaradeh_question_2020} in their work use types such as aggregation, ask, or listing to guide their construction of questions.

Beyond using question types for the development of benchmarks targeting \glspl{kg}, the literature also presents classifications of questions in other contexts. \textcite{li_learning_2002} propose a two-layered taxonomy for question classification in text-based \gls{qa}. Their classification is based on expected answer type semantics with six coarse classes, such as abbreviation, entity, or description, and 50 fine-grained classes. \textcite{moldovan_structure_2000} provide an extensive taxonomy for open-domain \gls{qa} systems, differentiating questions according to question classes, subclasses, answer types, and focus. Furthermore, \textcite{dillon_classification_1984} provides a theoretical discussion and philosophical perspective on the classification of research questions. This approach is based on the kinds of knowledge a question entails, proposing a categorical scheme such as character descriptions, questions of identification, and conditional questions. On a similar note, \textcite{thuan_construction_2019} examine the construction and formulation of research questions specifically in \gls{dsr}. They propose a taxonomy of question classification, including the types of problem-solving, gap-spotting, and problematization. 

While these \gls{kgqa} datasets \cite{dubey_lc-quad_2019,auer_sciqa_2023,banerjee_dblp-quad_2023,jaradeh_question_2020} provide crucial benchmarks for evaluating \gls{qa} system capabilities across diverse question complexities, they primarily offer classifications tailored to their respective datasets, underlying knowledge graphs, or generation methodologies. None of these works specifically focuses on taxonomy creation itself. Instead, they present question types primarily as a secondary component that supports dataset construction. Consequently, these works do not present or refer to a comprehensive, generalized taxonomy for scholarly \gls{kgqa} specifically designed for the literature search task. While other classification schemes exist \cite{li_learning_2002,moldovan_structure_2000,dillon_classification_1984,thuan_construction_2019}, they are not specifically designed for the nuances of scholarly \gls{kgqa}. Therefore, an overarching taxonomy for scholarly \gls{kgqa} in the literature search context is still a missing element in the current research landscape. Our Contribution \hyperref[enum:c2]{\textbf{C2}} addresses this gap by synthesizing existing classifications from the literature to form a comprehensive taxonomy.
