\glsresetall    
\chapter{Introduction}
\label{ch:introduction}

% \glspl{llm} like GPT-4 \cite{openai_gpt-4_2024} and Flan-T5 \cite{chung_scaling_2022} sparked a revolution in the field of natural language processing tasks. These models are built on the transformer architecture \cite{vaswani_attention_nodate} and trained on extensive datasets scaled to billions of parameters, which leads to remarkable abilities in zero-shot learning, step-by-step reasoning, in-context learning, instruction following, human alignment, and tool manipulation \cite{yang_give_2024}. 

% Providing textual answers to user questions, relieve users of the cognitive effort of collecting the needed information from individual search results themselves.

% Question answering is a retrieval task more challenging than common search engine tasks because its purpose is to find an accurate and concise answer to a question rather than a relevant document. The difficulty is more acute in tasks such as story comprehension in which the target text is less likely to overlap with the text in the questions. For this reason, advanced natural language techniques rather than simple key term extraction are needed. \cite{Learning Question Classifiers by Xin Li}

% GraphRAG is still in its early stages \cite{peng_graph_2024}

\input{chapters/1_introduction/sections/1_motivation}
\input{chapters/1_introduction/sections/2_problem_statement}
\input{chapters/1_introduction/sections/3_objective}
\input{chapters/1_introduction/sections/4_research_contributions}
\input{chapters/1_introduction/sections/thesis_outline.tex}